\documentclass{article}
\usepackage{cite}
\usepackage{tikz}
\usepackage{todonotes}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{hyperref}
\usetikzlibrary{arrows,decorations.pathmorphing,shapes.multipart,automata,positioning,shapes}

\hyphenation{Schwell-werte}
% =============== Definitionen =========
\newcommand{\var}[1]{{\em #1}}

\newenvironment{definition}
    [1]
    {
        {\bf Definition:} #1\\
    }
    {}

\newcommand{\defined}
    [1]
    {
        {\bf #1}
    }
% ======================================

% =============== Requirements =========
\newcounter{requirementscount}{}
\setcounter{requirementscount}{0}
\newcommand{\requirement}[1] {
        \addtocounter{requirementscount}{1}
        {\bf Requirement \therequirementscount:} #1\\
    }

% =============== PHASES ===============
\newcounter{ycounter}{}
\newenvironment{phases}
{
\setcounter{ycounter}{-1}
\begin{tikzpicture}[node distance=3cm,text width=3cm,
    box/.style={shape=rectangle,draw}, scale=0.7, transform shape]
}
{\end{tikzpicture}}

\newcommand{\nomoreheaders} {
    \addtocounter{ycounter}{-1}
}

\newcommand{\aliceheader}[1] {
\node at (-4,\theycounter) {#1}
}
\newcommand{\bobheader}[1] {
\node at (4,\theycounter) {#1}
}

\newcommand{\aliceknowledge}[2][0]{
\node[box]
    at (-4+#1, \theycounter)
    {#2}
}
\newcommand{\bobknowledge}[2][0]{
\node[box]
    at (4+#1, \theycounter)
    {#2}
}

\newcommand{\symmetricknowledge}[2][0]{
\aliceknowledge{#2};
\bobknowledge[#1]{#2};
}


\newcommand{\phase}[1]{
\addtocounter{ycounter}{-1};
\draw[->,decorate,decoration={snake,amplitude=1mm,post length=2mm}]
    (0,\theycounter) -- ++(0,-2)
    node [right,midway,xshift=3mm] {#1};
\addtocounter{ycounter}{-3};
}
% ======================================

\author{Gudrun Amedick, Tim Kunold, Harald Kr\"amer}
\title{Spezifikation des verteilten, privaten Lerners}
\date{}
\begin{document}
\maketitle
\pagebreak
\tableofcontents
\pagebreak
\section{Einleitung}
Dieses Dokument spezifiziert die im Projekt zu implementierende Anwendung.
Die Spezifikation definiert eine gewisse Anzahl von Akzeptanzkriterien,
die bei der Abgabe demonstrierbar sein m\"ussen. Als Demonstration ist
eine Demo, eine glaubhafte Code-Inspektion oder automatisierte Tests tauglich.\\
Im ersten Teil des Dokumentes werden die verwendeten Begriffe festgelegt,
sowie die Annahmen, auf denen die Geheimhaltung der Daten jedes Anwenders beruhen.
Danach werden zun\"achst gewisse technische Grundlagen gekl\"art, um danach
die einzelnen Schritte in der Anwendung festzulegen.

\subsection{Begriffe}
\begin{definition}{Eigenes,Gesamtes}
\(M\) sei eine Menge von Elementen, die in zwei Teilmengen \(M_A\)
und \(M_B\) zerf\"allt, sodass \(M = M_A \cup M_B\) ist. Wir nehmen
desweiteren an, dass Alice \(M_A\) kennt, aber weder \(M\) noch \(M_B\)
und dass foo Bob \(M_B\) kennt, aber weder \(M\) noch \(M_A\). Dann bezeichnen
wir:
\begin{itemize}
\item \(M\) als \defined{gesamtes} Wissen
\item \(M_A\) als das \defined{eigene} Wissen von Alice
\item \(M_B\) als das \defined{eigene} Wissen von Bob
\item \(M_B\) als das \defined{andere} Wissen von Alice
\item \(M_A\) als das \defined{andere} Wissen von Bob
\end{itemize}
\end{definition}
\begin{definition}{Gemeinsam}
Wenn beide Anwender das gleiche Wissen w haben, dann bezeichnen wir w
als \defined{gemeinsames Wissen}. 
\end{definition}\\
\begin{definition}{Vorwissen}
Wenn Anwender verschiedene Phasen hintereinander ausf\"uhren, dann bezeichnen
wir das Wissen aus den bereits ausgef\"uhrten Phasen als \defined{Vorwissen}.
\end{definition}\\

\begin{definition}{Entscheidungsbaum}\\
Generell lassen sich Entscheidungsb\"aume wie folgt definieren: Es gibt eine
Menge \(A\) von diskreten Attributen \({A_1, A_2, \dots, A_n}\) mit Werten
\(values(A_i) = {v^1_i, v^2_i, \dots, v^w_i}\) und es gibt zu erkennde
Klassen \(K = {K_1, K_2, \dots, K_k}\). Es bezeichne im Folgenden desweiteren
\(Values = \bigcup_{A_i} values(A_i)\) die Menge aller m\"oglichen 
Attributwerte (dies vereinfacht einige Definitionen, auch wenn 
einige Typen etwas ungenauer werden).
Dann kann die Menge \(T\) von Entscheidungsb\"aumen induktiv definiert werden 
als:
\( T = (A \times Values \mapsto T) \cup K\)\\
Ein Entscheidungsbaum klassifiziert eine Abbildung der Attribute auf Werte.
Dieser klassifizierungsvorgang ist induktiv definiert. Wenn der
zu klassifizierende Kandidat mit \(s : A \mapsto Values\)
bezeichnet wird, dann ergibt sich als Auswertungsfunktion
\(evaluate : (A \mapsto Values) \times T \mapsto K\):

\begin{align}
evaluate(s, (A_i, f)) &=& evaluate(s, f(s(A_i)))\\
evaluate(s, K_i) &=& K_i
\end{align}
\end{definition}

Verbal beschrieben besteht ein Entscheidungsbaum also aus Bl\"attern,
die aussagen, dass alle zu klassifizierenden Objekte, die dieses Blatt 
,,erreichen'' zu dieser bestimmten Klasse geh\"oren und \"Asten, 
die mit einem Attribut annotiert sind und zu jedem m\"oglichen 
Wert des Attributes einen Unterbaum haben. Bei der Klassifizierung 
werden dann die \"Aste entsprechend der Attributwerte des zu 
klassifizierenden Objektes traversiert, bis ein Blatt erreicht 
wird und die Klassifizierung abgeschlossen ist.\\
Wenn wir beispielsweise annehmen, dass wir uns bei der Spamerkennung dadrauf
geeinigt haben, dass wir als Attribute verwenden, ob die Worte "Foo" bzw
"Bar" oft oder selten vorkommen, dann w\"urden die
E-Mail-Datenbanken transformiert werden zu einem Vektor von Abbildungen
von Foo und Bar auf oft oder selten:\\
\begin{tabular}{c c}
Vorkommnisse Foo & Vorkommnisse Bar \\
Oft & Oft \\
Selten & Oft \\
Selten & Selten \\
\end{tabular}
Ein m\"oglicher Entscheidungsbaum ist in Abbildung ~\ref{fig:decision_tree_example} 
dargestellt, der die Mails in Spam und Nicht Spam klassifiziert. Es ist hier ein
Baum aufgezeichnet, der prinzipiell nur Mails als ,,Nicht Spam'' klassifiziert,
wenn sie oft Foo und Bar enthalten. In der Grafik ist zudem illustriert, welche 
Knoten und damit welche Kanten bei der Auswertung betrachtet wurden.
\begin{figure}
\begin{tikzpicture}
[branch/.style={shape=rectangle,draw},
 leaf/.style={shape=ellipse,draw},>=stealth']
\node[branch] (foo) [color=red,dashed] {Vorkommnisse von Foo};
\node[leaf] (spam1) [below left=of foo] {Spam};
\node[branch] (bar) [color=red,dashed] [below right=of foo] {Vorkommnisse von Bar};
\node[leaf] (spam2) [below left=of bar] {Spam};
\node[leaf] (spam3) [color=red,dashed,below right=of bar] {kein Spam};

\draw[->] (foo) to node[above]{Selten} (spam1);
\draw[->,dashed,color=red] (foo) to node[above] {Oft} (bar);
\draw[->] (bar) to node[above] {Selten} (spam2);
\draw[->,dashed,color=red] (bar) to node[above] {Oft} (spam3);
\end{tikzpicture}
\caption{M\"oglicher Entscheidungsbaum, Klassifizierung von 
,,Foo \(\rightarrow\) Oft, Bar \(\rightarrow\) Oft''}
\label{fig:decision_tree_example}
\end{figure}\\

\begin{definition}{Attribut}
Wir definieren eine Menge von Wahrscheinlichkeiten 
\(P = [0, 1] \subset \mathbb{R}\) und eine Menge von Buchstaben 
\(\Sigma = \{a, b, \dots, z, A, B, \dots, Z\}\).
Damit definieren wir ein \defined{Attribut} als 
\(\Sigma^+ \times P \times P\). Wenn ein Attribut \(A = (w, l, h)\) gegeben ist,
bezeichnen wir w als \defined{Wort}, l als \defined{unterer Schwellwert} und h
als \defined{oberer Schwellwert}. Es wird desweiteren von allen Attributen
gefordert, dass \(l \leq h\) ist.
\end{definition}\\
\begin{definition}{Wahrheitstafel}
F\"ur eine boolsche Funktion ist eine \defined{Wahrheitstafel} eine Tabelle,
die f\"ur jede Kombination der Eingaben genau eine Ausgabe der beschriebenen
Funktion definiert.
\end{definition}\\
\begin{definition}{entstellte Wahrheitstafel}
Gegeben sei eine Wahrheitstafel mit Eingabevariablen 
\(\{i_1, i_2, \dots, i_n\}\) und Ausgabevariable o und wir 
 stellen f\"ur jede Variable v eine bijektive
 Verschleierung \(f_v : {0, 1} \mapsto \mathbb{Z}\) auf. 
Dann entsteht eine entstellte Wahrheitstafel f\"ur W, wenn
 wir f\"ur jede Zeile in der Wahrheitstafel die verschleierte Ausgabe
 mittels einer symmetrischen Verschl\"usselung mit den 
 verschleierten Werte der Eingangsvariablen in einem 
 Verschl\"usselungsschritt pro Eingangsvariable verschl\"usseln.
Es ist notwendig zu bemerken, dass eine Implementierung
 einen Weg anbieten muss, eine sinnlose Verschl\"usselung
 zu erkennen.\\
Wenn also beispielsweise in einer Wahrheitstafel die Eingaben 
 1 und 1 auf 1 abgebildet werden und die erste Eingabevariable
 verschleiert 1 als 23, die zweite Eingabevariable verschleiert
 1 als 49 und die Ausgabevariable verschleiert 1 als 12 und E
 ist die symmetrische Verschlueselung, dann
 ist das daraus entstehende Element der entstellten Wahrheitstafel
 \(E_{f_{i_1}(1)}(E_{f_{i_2}(1)}(f_o(1))) = E_{49}(E_{23}(12))\)
\end{definition}\\
\begin{definition}{Schaltkreis}
Wir definieren einen \defined{Schaltkreis} als einen gerichteten azyklischen 
 Graphen.
Die Knoten dieses Graphen sind annotiert mit Wahrheitstafeln. 
Die Kanten sind eingeteilt in \defined{Eingabekanten}, \defined{innere Kanten} 
 und \defined{Ausgangskanten}.
Der Wert einer Eingabekante wird vom Anwender zu Beginn festgelegt. 
Der Wert einer inneren Kante oder einer Ausgangskante ergibt sich durch
 anwenden der Wahrheitstafel auf die Eingangskanten. 
Da wir nur boolsche Schaltkreise mit den Knotenannotationen ,,and'',
 ,,or'', ,,xor'' und ,,not'' brauchen und all diese Funktionen entweder
 un\"ar oder kommutativ sind, brauchen wir keine Ordnung der Eingabekanten
 festlegen.
\end{definition}\\
\begin{definition}{Entstellter Schaltkreis}
Ein \defined{entstellter Schaltkreis} entsteht aus einem normalen Schaltkreis,
 indem jede an einen Knoten annotierte Wahrheitstafel entstellt wird, wenn
 dabei garantiert wird, dass f\"ur die Verbindung einer Ausgangsvariablen
 o mit einer Eingangsvariablen i auf beide Variablen die gleiche
 Verschleierung angewendet wird.\\
Desweiteren wird f\"ur jede Eingabekante die Verschleierungsfunktion
 gespeichert, um die Eingabe des Schaltkreises kodieren zu k\"onnen und
 f\"ur jede Ausgangskante die Inversion der Verschleierungsfunktion
 gespeichert, um die Ausgabe dekodieren zu k\"onnen.
\end{definition}
\subsection{Annahmen}
Wir nehmen im Folgenden an, dass die Anwender ehrlich sind.
Das bedeutet, dass die Anwender zwar versuchen, aus den Informationen,
die sie im Protokoll erhalten, m\"oglichst viel zu lernen, allerdings
werden sie sich an das Protokoll halten. (d.h., eine Annahme der Form
,,Jetzt sendet Alice diesen Wert erneut'' funktioniert).

\pagebreak
\section{Grundlagen der Anwendung}
Gegeben diese Begrifflichkeiten ist dann die Vision der Anwendung, dass
aus den gesamten E-Mails ein gemeinsamer Klassifikator erzeugt wird,
wobei \"uber die eigenen E-Mails jedes Anwenders m\"oglichst wenig preisgeben
m\"ochte. Genauer gesagt, es soll nur der Klassifikator \"uber die eigenen 
E-Mails preisgegeben werden.

\subsection{Form der Benutzereingabe}
Da wir nicht mit weiteren Informationen der E-Mail arbeiten, sondern nur mit
dem textuellen Inhalt, w\"ahlen wir als Eingabeform der E-Mails einfache
Textdateien. Um die E-Mails einfach nach Spam und Nicht Spam organisieren
zu k\"onnen, verlangt die Anwendung, dass in einem Verzeichnis, aus
dem wir E-Mails einlesen sollen, zwei  Verzeichnisse ,,spam'' und ,,not\_spam'' 
existieren, welche dann die Dateien mit den E-Mail-Inhalten enthalten.
Weitere Unterverzeichnisse in irgendeinem beteiligten Verzeichnis werden
von der Anwendung ignoriert. Dadurch ist es nicht notwendig, die Metadaten
aus einer separaten Datei einzulesen (und diese separate Datei auf dem
neuesten Stand zu halten), sondern die Existenz einer Datei in einem der
beiden Verzeichnisse schreibt sofort die Klassifkation der Datei vor.

Der Anwender kann dann \"uber einen Parameter steuern, ob der Klassifikator
auf der Standardausgabe ausgegeben wird oder in welche Datei der Klassifikator
geschrieben werden soll.

\subsection{Interaktion der verteilten Programme}
Wir implementieren die Kommunikation der verteilten Programme dadurch, dass
wir das Programm in zwei verschiedenen Modi ausf\"uhrbar machen: Als Client
und als Server. Der Server wird dann im Allgemeinen die Aufgabe von Bob 
erf\"ullen und auf Anfragen des Clients antworten, der dann nat\"urlich die
Rolle von Alice einnimmt. Der Client wird dann zudem die IP und den Port
des Server vom Anwender erfahren, um mit dem Server kommunizieren zu k\"onnen.

\subsection{\"Ubertragung der Gesamtanzahl der E-Mails}
Aus technischen Gr\"unden wird zu Anfang der Anwendung von jedem der beiden
Anwender die Gesamtanzahl der eigenen E-Mails \"ubertragen. Dies stellt kein
Risiko f\"ur die Geheimhaltung dar, da die Anzahl der E-Mails keine Aussage
\"uber den Inhalt der E-Mails preisgibt.

\subsection{Phasen der Anwendung}
Die Anwendung durchl\"auft bei der Berechnung mehrere Phasen, die aufeinander
aufbauen. Der Ablauf dieser Phasen ist in Abbildung \ref{fig:phases}
illustriert. In der ersten Phase bererechnen beide Anwender die gemeinsame 
Wortliste, aus denen dann in einer zweiten Phase Schwellwerte und damit
Attribute f\"ur einen Entscheidungsbaum berechnet werden. In einer
dritten Phase wandeln dann beide Anwender ihre eigenen E-Mails in die
Attributwert-vektoren um und berechnen dann in einer finalen Phase 
den gemeinsamen Klassifikator.
\begin{figure}
\centering
\begin{phases}
\aliceheader{Alice};
\bobheader{Bob};
\nomoreheaders
\aliceknowledge[-2]{eigene E-Mails};
\bobknowledge[-2]{eigene E-Mails};

\aliceknowledge[2]{Einordnung von eigenen E-Mails als Spam, Nicht Spam};
\bobknowledge[2]{Einordnung von eigenen E-Mails als Spam, Nicht Spam};

\phase{Phase 1: Finden der gemeinsamen Wortliste};

\symmetricknowledge{Gemeinsame Wortliste};

\phase{Phase 2: Finden der gemeinsamen Schwellwerte};

\symmetricknowledge{Gemeinsame Attribute = Liste von (Wort + Schwellwerte)};
\phase{Phase 3: Diskretisieren der eigenene E-Mails};

\symmetricknowledge{Eigene diskretisierte E-Mails};

\phase{Phase 4: Lernen der gesamten E-Mails};

\symmetricknowledge{Gemeinsamer Klassifikator};
\end{phases}
\caption{Phasen der Anwendung}
\label{fig:phases}
\end{figure}


\pagebreak % XXX: if possible, kill this pagebreak
\section{Finden der gemeinsamen Wortliste}
In dieser Phase berechnen die beiden Parteien aus den gesamten E-Mails
eine gemeinsame Wortliste, die mit grosser Wahrscheinlichkeit 
aussagekr\"aftige Attribute f\"ur den Entscheidungsbaum liefert. 
Die Phase besteht aus zwei Schritten.
Im ersten Schritt berechnen beide Parteien getrennt eine eigene Wortliste.
Jedes Wort auf dieser Liste hat in den eigenen E-Mails hat eine starke 
 Aussagekraft \"uber die Klassifikation der E-Mails, die das Wort
 oft enthalten.
Im zweiten Schritt vereinen beide Parteien ihre eigenen Wortlisten, um 
 die gemeinsame Wortliste zu berechnen. 
Dieser Vorgang ist in Abbildung ~\ref{fig:phase:two} illustriert.

\begin{figure}
\begin{phases}
\aliceheader{Alice};
\bobheader{Bob};
\nomoreheaders

\aliceknowledge[-2]{eigene E-Mails};
\bobknowledge[-2]{eigene E-Mails};

\aliceknowledge[2]{Einordnung von eigenen E-Mails als Spam, Nicht Spam};
\bobknowledge[2]{Einordnung von eigenen E-Mails als Spam, Nicht Spam};
\phase{Phase 1.1.1: Berechnung der Anteile der Worte in eigenen Spam/Nicht Spam E-Mails};
\symmetricknowledge[1]{Liste von (Wort + Anteil der Vorkomnisse eines Wortes an allen eigenen Worten)};
\phase{Phase 1.1.2: Auswahl der N besten eigenen Worten nach Informationsheuristik};
\symmetricknowledge{Eigene Wortliste}
\phase{Phase 1.2: Synchronisierung der Wortlisten}
\symmetricknowledge{Gemeinsame Wortliste}
\end{phases}
\caption{Ablauf der Phase zum Berechnen der gemeinsamen Wortliste}
\label{fig:phase:two}
\end{figure}

\subsection{Berechnung der Anteile an den Wortmengen}
Wir verwenden eine Heuristik f\"ur den Informationsgehalt des Vorkommens eines
Wortes in einer E-Mail, die auf dem Verh\"altnis der Vorkommnisse des 
Wortes zu der Gesamtanzahl Worte in einer Klasse basiert. 
Um diese zu berechnen werden konzeptionell alle Worte in E-Mails einer Klasse 
 zu einer Multimenge hinzugef\"ugt. 
F\"ur jedes Wort in dieser Multimenge ist das Verh\"altnis der
Vielfachheit des Wortes zur M\"achtigkeit der Multimenge das gesuchte
Verh\"altnis.
Damit ergibt sich folgendes Akzeptanzkriterium:\\
\requirement{Wenn die Spam-Mails die Mails "Foo Bar", "Foo Bar", "Foo Foo"
und "Foo" sind und die Nicht-Spam-Mails "Bar Bar", "Foo" und "Bar", 
dann muss diese Phase die folgende Tabelle berechnen:\\
\begin{center}
\begin{tabular}{c c c}
Wort & Spam-Anteil & Nicht-Spam-Anteil \\
Foo & \(\frac{5}{7}\) & \(\frac{1}{4}\) \\
Bar & \(\frac{2}{7}\) & \(\frac{3}{4}\)
\end{tabular}
\end{center}
Eine Approximation der Werte durch Fliesskommazahlen ist
ebenfalls akzeptabel.}

\subsection{Auswahl der Worte nach Informationsheuristik}
Wir wollen nun Worte ausw\"ahlen, deren h\"aufiges Vorkommen in einer
 E-Mail viel \"uber die Klasse der E-Mail aussagen.
Wir verwenden dabei eine deduktive Heuristik, die annimmt, dass die
 Wahrscheinlichkeit, dass eine E-Mail zu einer Klasse geh\"ort, direkt
 mit den Wahrscheinlichkeiten zusammenh\"angt, dass die W\"orter in
 dieser E-Mail zu dieser Klasse geh\"oren. 
Das bedeutet, wir wollen Worte selektieren, bei denen genau eine 
 Wahrscheinlichkeit, zu einer Klasse zu geh\"oren, drastisch unterschiedlich
 ist.\\
Eine m\"ogliche Quantifizierung dieser Unterschiedlichkeit ist im bin\"aren
 Fall \(\Delta(x, y) = \|x - y\|\).
Diese Quantifizierung hat die Eigenschaft, f\"ur 
 x = 1 und y = 0 bzw x = 0 und y = 1 maximal 1 zu sein, und f\"ur identische 
 x und y 0 zu sein. 
Da x und y f\"ur die Belegung (0, 1) bzw (1, 0) wirklich maximal weit 
 auseinander liegen und bei gleichen Werten wirklich die gerinstm\"ogliche
 Aussage \"uber die Klassezugeh\"origkeit eines Wortes getroffen wird, 
 ist dies wirklich eine Quantifizierung der Aussagekraft, die wir anstreben. 
Damit w\"ahlen wir die aussagekr\"aftigstenen Worte aus, indem wir alle Worte 
    nach 
\(\Delta(\mathrm{Vorkommen~in~Spam-E-Mails}, 
         \mathrm{Vorkommen~in~Nicht-Spam-E-Mails})\) 
 absteigend sortieren und die ersten N Worte w\"ahlen. 
Damit ergibt sich folgendes Akzeptanzkriterium:\\
\requirement{Wenn N = 2 ist, und als Worte mit Vorkomnissen gegeben sind:
\begin{center}
\begin{tabular}{c c c}
Wort & Vorkomnisse in Spam-E-Mails & Vorkommnisse in Nicht-Spam-Emails \\
A & 0.5 & 0.5 \\
B & 0.2 & 0.2 \\
C & 0.3 & 0.5 \\
D & 0.2 & 0.8 \\
E & 0.9 & 0.2
\end{tabular}
\end{center}
dann werden als Wortliste D und E gew\"ahlt.}

\subsection{Zusammenfassen der Wortlisten}
Wir haben nun zwei separate, lokale Wortlisten berechnet. Diese m\"ussen
zusammengefasst werden zu einer gemeinsamen Wortliste. Da wir annehmen, dass
die Benutzer ehrlich sind, k\"onnen wir annehmen, dass die Benutzer als
Eingabe dieses Protokolles keine beliebige Liste festlegen und auch ihre
Daten nicht so manipulieren, dass eine bestimmte Wortliste versendet wird.
Zudem werden die Attribute des Baumes \"offentlich sein, sodass eine
Geheimhaltung der Wortlisten keinen Sinn macht.
Deswegen k\"onnen wir die Wortlisten durch eine einfache Vereinigung der
separaten Wortlisten zu einer gesamten Wortliste vereinigen. Deswegen wird 
das Zusammenfassen der Wortliste implementiert, indem beide Anwender ihre
lokale Wortliste an den jeweils anderen Anwender versenden und beide 
Anwender lokal die Wortlisten vereinigen. Damit ergibt sich folgendes
Akzeptanzkriterium:\\
\requirement{Wenn Alice die Wortliste A, B, C berechnet hat, und Bob die
Wortliste C, D, E berechnet hat, dann muss die zusammengefasste Wortliste
A, B, C, D, E sein.} 

Abschliessend ergibt sich somit das Akzeptanzkriterium:\\
\requirement{Das Protokoll, in dem beide Anwender ihre Wortlisten einander
zusenden und lokal die spezifizierte Syncronisierung durchf\"uhren, ist
implementiert}

\pagebreak % XXX: if possible, kill this pagebreak
\section{Finden der gemeinsamen Schwellwerte}
\begin{figure}
\begin{phases}
\aliceheader{Alice};
\bobheader{Bob};
\nomoreheaders

\aliceknowledge[-2]{Vorwissen};
\aliceknowledge[2]{Gemeinsame Wortliste};

\bobknowledge[-2]{Vorwissen};
\bobknowledge[2]{Gemeinsame Wortliste};
\phase{Phase 2.1: Berechnung der Vorkommnisse der Worte in eigenen Spam/Nicht Spam E-Mails};
\symmetricknowledge[1]{Eigene Liste von (Wort + Anteil der Vorkomnisse eines Wortes an Spam/Nicht-Spam Worten)};
\phase{Phase 2.2: Bestimmung eines Schwellwertes, der Spam, Nicht-Spam Anteile m\"oglichst halbiert};
\symmetricknowledge{Eigene Liste von (Wort + Schwellwert)};
\phase{Phase 2.3: Synchronisierung der Schwellwerte};
\symmetricknowledge{Gemeinsame Liste von (Wort + Schwellwerte)};
\end{phases}
\caption{Ablauf der Phase zum finden der gemeinsamen Schwellwerte}
\label{fig:phase2}
\end{figure}
In dieser Phase m\"ussen wir f\"ur jedes Wort in der gemeinsamen Wortliste
Schwellwerte finden, wann das Wort besonders oft oder besonders selten
vorkommt. Jeder Anwender berechnet dazu zun\"achst einen eigenen
Schwellwert f\"ur jedes Wort und in einem zweiten Schritt werden diese
eigenen Schwellwerte mit den jeweils anderen Schwellwerten vereint, um
die gemeinsamen Schwellwerte und somit die gemeinsamen Attribute zu
berechnen. Diese Schritte sind in Abbildung \ref{fig:phase2} illustriert.

\subsection{Bestimmung der eigenen Schwellwerte}
Es muss nun f\"ur ein Wort \(w\) eine Schwelle gefunden werden, ab wann das
Wort w in einer E-Mail oft vorkommt. Wir w\"ahlen hierzu den Mittelwert
der Vorkomnisse des Wortes in allen eigene E-Mails eines Anwenders, da wir
dann die Begriffe ,,\"uberdurchschnittlich oft'' bzw ,,unterdurchschnittlich 
oft''als eigenen Schwellwert quantifizieren.
Damit ergibt sich folgendes Akzeptanzkriterium:\\
\requirement{Wenn die E-Mails "A A A", "A B B", "A C C" und "A A C" sind, dann
muss die Software als eigenen Mittelwert f\"ur das Wort A 
\(\frac{1}{4} \cdot (1 + \frac{1}{3} + \frac{1}{3} + \frac{2}{3}) = \frac{7}{12}\) bestimmen.}

\subsection{Syncronisierung der Schwellwerte}
Wir haben nun von Alice und Bob jeweils einen Schwellwert a und einen
Schwellwert b, sodass Alice der Meinung ist, dass ein Wort \(w\)
selten vorkommt, wenn der Anteil an Vorkomnissen unter a liegt und
Bob der Meinung ist, dass das Wort selten vorkommt, wenn der Anteil an
Vorkommnissen unter b liegt. Wir syncronisieren dann die Werte zu einem
aufsteigend sortierten Paar von schwellwerten (a, b) bzw (b, a). oBdA sei
\(a \leq b\). Dann gilt, dass bei weniger Vorkommnissen als a beide Anwender
sich einig sind, dass das Wort selten vorkommt, w\"ahrend bei mehr Vorkommnissen
als b beide Anwender sich einig sind, dass das Wort oft vorkommt. Dazwischen 
herrscht uneinigkeit und es wird angenommen, dass die weiter Klassifikation
durch einen Entscheidungsbaum diese Uneinigkeit aufl\"osen kann.\\
Damit ergeben sich als Akzeptanzkriterien:\\
\requirement{Wenn a = 0.2 ist und b = 0.4, dann ist das Schwellwertpaar
(0.2, 0.4)}\\
\requirement{Wenn a = 0.5 ist und b = 0.4, dann ist das Schwellwertpaar
(0,4, 0.5)}\\
\requirement{Wenn a = b = 0.5 ist, dann ist das resultierende Schwellwertpaar
(0.5, 0.5)}\\
Da die Attribute am Ende \"offentlich bekannt sind, implementieren wir
dies, indem sich beide Anwender die eigenen Schwellwerte f\"ur die Worte
zuschicken und dann lokal die Syncronisierung berechnen. Somit ergibt
sich noch das abschliessende Akzeptanzkriterium:\\
\requirement{Das Protokoll, indem beide Anwender ihre eigenen Schwellwerte
an den jeweils anderen Anwender senden und dann die bereits spezifizierte
Merge-Operation ausf\"uhren ist implementiert.}

\pagebreak % XXX: if possible, kill this pagebreak
\section{Diskretisieren der eigenen E-Mails}
In dieser Phase muss die Anwendung die E-Mail-Inhalte, d.h., Texte ind
die Attributvektoren umrechnen, auf denen der ID3-Algorithmus operiert.
Dazu muss f\"ur einen E-Mail-Inhalt f\"ur jedes Wort in den Attributen
der Anteil an den Worten in dem gesamten E-Mail-Inhalt berechnet werden
und dann anhand des Schwellwertpaares als selten, oft oder mittel
klassifiziert werden. Dies ist in Abbildung \ref{fig:phase3} illustriert.
Da dies eine relativ einfache und vor allem lokale Phase ist, werden
hier nur die Anforderungen aufgelistet:\\
\requirement{Wenn der E-Mail-Inhalt "A A A A B B C D" ist und die Attribute
sind (A, 0.2, 0.3), (B, 0.1, 0.9), (C, 0.5, 0.8),
dann wird diese E-Mail diskretisiert in den Vektor oft, mittel, selten}

\begin{figure}
\begin{phases}
\aliceheader{Alice};
\bobheader{Bob};
\nomoreheaders;
\aliceknowledge[-2]{Vorwissen};
\aliceknowledge[2]{Gemeinsame Attribute = Liste von (Wort + Schwellwerte)};

\bobknowledge[-2]{Vorwissen};
\bobknowledge[2]{Gemeinsame Attribute = Liste von (Wort + Schwellwerte)};

\phase{Phase 3: Diskretisieren der eigenene E-Mails};
\symmetricknowledge{Eigene diskretisierte E-Mails};
\end{phases}
\label{fig:phase3}
\caption{Ablauf der Phase zum diskretisieren der eigenen E-Mails}
\end{figure}

\pagebreak % XXX: if possible, kill this pagebreak
\section{Lernen der gesamten E-Mails}
Das verteilte Lernen der gesamten E-Mails ist bei weitem der komplexeste
Schritt in der Anwendung. Auf einer sehr abstrakten Ebene ist dieser
Schritt jedoch eine direkte Umsetzung des ID3-Algorithmus' auf den
privaten, verteilten Fall. Das bedeutet, der Algorithmus arbeitet
rekursiv auf einer Menge von Daten und einer Menge von verbleibenden
Attributen und unterscheidet dann drei F\"alle:
\begin{itemize}
\item Es gibt keine weiteren Attribute. In diesem Fall wird die
ein Blatt mit der dominierenden Ausgabe erzeugt Dies ist in
Abbildung \ref{fig:id3:case1} illustriert und in Sektion 
\ref{sec:id3:case1} genauer spezifiziert.
\item Alle Datens\"atze sind sich bez\"uglich der Ausgabe einig.
In diesem Fall wird ein Blattknoten mit der eindeutigen Ausgabe
erzeugt. Dies ist in Abbildung \ref{fig:id3:case2} illustriert und in 
Sektion \ref{sec:id3:case2} genauer spezifiziert.
\item Es herrscht noch Uneinigkeit bez\"uglich der Ausgabe
und es gibt noch weitere verwendbare Attribute. In diesem Fall
muss die Datenmenge anhand der Attributwerte eines Attributes
partitioniert werden, sodass der Informationsgewinn maximal ist
und die partitionen dann rekursiv behandelt werden. Dies ist in
Abbildung \ref{fig:id3:case3} illustiert und in Sektion \ref{sec:id3:case3} genauer
spezifiziert.
\end{itemize}
\subsection{Yaos Protokoll}
\begin{figure}
\begin{phases}
\aliceheader{Alice};
\bobheader{Bob};
\nomoreheaders
\aliceknowledge[-2]{Eigene Eingabe};
\aliceknowledge[2]{Schaltkreis};

\bobknowledge[-2]{Eigene Eingabe};
\bobknowledge[2]{Schaltkreis};

\phase{Y.1: Konstruktion des entstellten Schaltkreises und \"Ubertragung};
\aliceknowledge[-2]{Eingabekodierung};
\aliceknowledge[2]{entstellter Schaltkreis};
\bobknowledge{entstellter Schaltkreis};
\phase{Y.3 Alice schickt kodierte Eingabe an Bob};
\bobknowledge{Alice' kodierte Eingabe};
\phase{Y.4 Via Oblivious Transfer wird Bob's Eingabe kodiert};
\bobknowledge{Bob's kodierte Eingabe};
\phase{Y.5 Bob wertet Schaltkreis aus und sendet die Ausgabe an Alice};
\symmetricknowledge{Ausgabe} ;
\end{phases}
\caption{Ablauf von Yaos Protokoll}
\label{fig:yao}
\end{figure}
\paragraph{Generelles Vorgehen}
Der grobe Ablauf von Yaos Protokoll f\"ur die private zwei-Parteien Berechnung
ist in Abbidlung \ref{fig:yao} skizziert und basiert auf \cite{yaoprotocol}.
Die Eingabe jedes Anwenders f\"ur Yaos Protokoll ist eine Eingabe, und nach
Kerckhoffs Prinzip auch der auszuf\"uhrende Schaltkreis in Reinform. Einer
der beiden Anwender, ohne Beeintraechtigung der Allgemeinheit Alice, muss
nun aus diesem Schaltkreis einen enstellten Schaltkreis konstruieren. Dies
kann am einfachsten passieren, indem der Schaltkreis in einer Breitensuche
traversiert wird und die Kanten verschleiert werden. Das bedeutet, dass
in einem Schritt die zusammenh\"angenden Eingangs- und Ausgangsvariablen 
verschleiert werden. Dadurch werden die Anforderungen aus der Definition
der entstellten Schaltkreise erf\"ullt. Dabei kann dann auch erkannt
werden, dass eine Eingangsvariable bzw Ausgabevariable kein ,,anderes
Ende'' hat, d.h. diese Verschleierung in die Eingabekodierung bzw
Ausgabekodierung geschrieben werden muss. Dieser Schaltkreis und die
Ausgangskodierung wird dann an Bob \"ubertragen, w\"ahrend die
Eingangskodierung bei Alice verbleibt.
\paragraph{Verschleierung der Wahrheitstabellen}
Bei der Verschl\"usselung der Ausgaben verwenden wir ein einfaches XOR.
Um zu garantieren, dass wir Unsinnige Verschl\"usselungen erkennen k\"onnen,
erweitern wir jeden Tabelleneintrag um eine zweiten Tabelleneintrag, der 
aus einem analog zum Nutzeintrag verschl\"usselten Nullvektor besteht.
Wir bezeichnen diesen Eintrag als
Markierungseintrag. Dann ist es m\"oglich, diesen Eintrag
zu entschl\"usseln, zu \"uberpr\"ufen, ob dies der 0-Vektor ist und falls dies
der Fall ist, den Nutzeintrag zu entschl\"usseln. Der einzige Fall, wo dies
Probleme bereitet ist, wenn die bei zwei Eingaben die Verschleierungen 
genau kontr\"ar sind, da dann \(a \oplus b = 0 = b \oplus a\) gilt
und somit die Eingabe (0,1) und (1,0) die gleiche Ausgabe liefert. Dies
muss also beim Verschleiern verhindert werden, was jedoch kein Problem ist.
\paragraph{Belegung der Eingangskanten}
\subparagraph{Alice Eingabe}
Bob muss nun noch die Belegung der Eingangskanten lernen. Die
Eingabevariablen, die von Alice Eingabe belegt werden m\"ussen werden
belegt, indem Alice anhand der Eingangskodierung ihre Eingabe kodiert
und diesen String an Bob versendet. Da Bob keine Informationen dar\"uber
hat, welcher der beiden Verschleierungswerte f\"ur 0 oder f\"ur 1 steht,
erh\"alt Bob damit keine Informationen \"uber Alice Eingabe.
\subparagraph{Bobs Eingabe}
F\"ur die Kodierung von Bob's Eingabe muss etwas mehr Aufwand getrieben
werden, da weder Bob die Eingabekodierung lernen darf (weil er sonst
Alice Eingabe lernt), noch Alice Bob's Eingabe lernen darf (indem z.B.
Bob seine Eingabe an Alice schickt, damit Alice die Eingabe kodieren kann).
Daher wird dies durch eine Anwendung des 1-2-Oblivious-Transfers gel\"ost:
Alice bietet f\"ur jede von Bob zu belegende Eingabevariable die Werte
f\"ur 0 bzw 1 an, und Bob w\"ahlt mithilfe seines Eingabebits den richtigen
Wert aus. Aus den Eigenschaften von OT folgt, dass Alice nicht weiss, welchen
der beiden Werte Bob gew\"ahlt hat, und dass Bob den nicht gew\"ahlten Wert
nicht kennt. Somit ist die Sicherheit von Bobs Eingabe gegeben und 
sichergestellt, dass Bob wirklich seine Eingabe verwendet.

Wir implementieren den 1-2 Oblivious Transfer mittels RSA. Die Eingabe
von Alice seien \(m_1\), \(m_2\) und die Eingabe von Bob sei \(b\).
Alice ein Schl\"usselpaar, den privaten Exponenten e, den
\"offentlichen Exponenten d und sendet den Modulus N, d und zwei zuf\"allige
Nachrichten \(x_1\) und \(x_2\) an Bob. Bob w\"ahlt eine zuf\"allige Nachricht
k, verschl\"usselt k zu \(k'\) und sendet \(v = x_b + k' mod N\) an Alice. 
Alice berechnet nun \(k_0\) als Entschl\"usselung von \(v - x_0\) und 
\(k_1\) als Entschl\"usselung von \(v - x_1\) und sendet \(m_0 + k_0\) und
\(m_1 + k_1\) an Bob. Wenn Bob b = 0 gew\"ahlt hatte, kann Bob \(m_0\)
durch Subtraktion von \(k'\) von Alice erster Nachricht berechnen, und wenn
Bob b = 1 gew\"ahlt hatte, kann Bob \(m_1\) durch Subtraktion von \(k'\) von
Alice zweiter Nachricht berechnen. Das folgt (oBdA f\"ur b = 0) aus
\(m_0 + k_0 - k' = m_0 + D(v - x_0) - k' = m_0 + k' - k' = m_0\). Falls b 
nicht 0 war, heben sich in der Entschl\"usselung die Faktoren \(x_0\) und
\(x_1\) nicht auf und ein undefinierter Wert wird berechnet. \\
Danach kann Bob den Schaltkreis auswerten, indem er immer f\"ur eine 
Entscheidungstabelle, deren Eingabevariablen vollst\"andig belegt sind,
denjenigen Eintrag sucht, indem f\"ur jeden Eintrag der Markierungseintrag
entschl\"usselt wird und falls das Ergebnis 0 ist, der Nutzeintrag
entschl\"usselt wird und der Wert entsprechend weiterverwendet wird. Sobald
alle Ausgangsvariablen des gesamten Schaltkreises bekannt sind, kann anhand
der Ausgabedekodierung die Ausgabe in Klartext berechnet werden und Alice 
zugeschickt werden. (Hier wird wieder die Annahme des ehrlichen Anwenders
getroffen).

\subsection{Feststellen der dominierenden Ausgabe}\label{sec:id3:case1}
\begin{figure}
\begin{phases}
\aliceknowledge[-2]{Vorwissen};
\aliceknowledge[2]{Eigene diskretisierte E-Mails};

\bobknowledge[-2]{Vorwissen};
\bobknowledge[2]{Eigene diskretisierte E-Mails};

\phase{Phase 4.1: Feststellen der dominierenden Ausgabe};

\symmetricknowledge{gemeinsamer Blattknoten mit dominierender Ausgabe};
\end{phases}
\caption{ID3-Algorithmus, Fall 1: Keine Attribute mehr vorhanden}
\label{fig:id3:case1}
\end{figure}
Da die Menge der Attribute \"offentlich ist und die Menge der bereits
verwendeten Attribute ebenfalls \"offentlich ist, k\"onnen beide
Parteien erkennen, dass sie nun einen Blattknoten mit der dominierenden
Ausgabe konstruieren m\"ussen. Dazu ist es notwendig, zu erkennen,
ob in den verbleibenden E-Mails mehr Spam-E-Mails oder mehr Nicht-Spam-E-Mails
vorhanden sind. Dazu muss ein Schaltkreis designed werden, welcher als Eingabe
zwei Paare von Zahlen erh\"ahlt und als Ausgabe den Index der maximalen Summe
liefert. Da hierzu die Summe gebildet werden muss, muss hierzu die verwendete
Bitbreite bestimmt werden. Da jedoch beide Anwender die Anzahlen der von
ihnen verwendeten E-Mail-Mengen preisgegeben haben, kann jedoch die Summe
der verbleibenden Teilmengen abgesch\"atzt werden durch die Summe der
Anzahlen der gesamten E-Mails und somit kann die geasmte Bitbreite der
zu addierenden Zahlen abgesch\"atzt werden als Logarithmus dieser
Gesamtanzahl.\\
Dadurch verbleibt es dann, einen Schaltkreis zu designen, welcher zwei
Zahlen bekannter Bitbreite addiert und 0 bzw 1 ausgibt, wenn die erste
bzw zweite Zahl gr\"osser ist.
Da Effizienz erst einmal sekund\"ar ist, kann die Addition der Zahlen
 durch einen einfachen Riple-Carry-Adder vollzogen werden.\\
Die Maximumsbestimmung von zwei bin\"aren Zahlen ist dann die Frage,
 welche der beiden Zahlen die hoechstwertige 1 hat.
Wenn wir zudem definieren, dass die Ausgabe 0 bedeutet, dass die erste
 Zahl in den Paaren die kleinere ist und die Ausgabe 1 die zweite, dann
 vereinfacht sich die Maximumsbestimmung noch weiter zum finden der
 h\"ochstwertigen Stelle, die sich unterscheidet und dem zur\"uckgeben
 des Bits in der ersten Zahl. Dies ist in Abbildung ~\ref{fig:circuit:max sum}
 angedeutet.\\
Formal gilt also:
 \(lt(a, b) = b_i \Leftrightarrow a_i \neq b_i \wedge \forall k = i+1,\dots,n: a_k = b_k\)
Der Allquantor ist als Kaskade von Und-Gattern implementierbar und die Gleichheit
 bzw Ungleichheit als Negation bzw direkte Verwendung des XOR-Gatters implementierbar,
 damit kann diese Formel einfach in einen Schaltkreis \"uberf\"uhrt werden.\\
\begin{figure}
\centering
\begin{tikzpicture}
[>=stealth']
\node at (-4, 5) {Alice: Spam E-Mails, Nicht-Spam E-Mails};
\node at (4, 5) {Bob: Spam E-Mails, Nicht-Spam E-Mails};
\node[shape=circle,draw] (spamaddition) at (-1, 2) {+};
\node[shape=circle,draw] (useaddition) at (1, 2) {+};
\node (spamvector) [rectangle split, rectangle split parts=4, draw] at (-1, 0)
{
MSB
\nodepart{second}
0
\nodepart{third}
1
\nodepart{fourth}
\(\vdots\)
};
\node at (-3.2,0) {Anzahl Spam-Mails};

\node(usevector) [rectangle split, rectangle split parts=4, draw] at (1, 0)
{
MSB
\nodepart{second}
0
\nodepart{third}
0
\nodepart{fourth}
\(\vdots\)
};
\node at (3.6,0) {Anzahl Nicht-Spam-Mails};

\draw[->] (spamaddition) to (spamvector);
\draw[->] (useaddition) to (usevector);
\draw (-5, 4.8) -- (-5, 3) -- (3, 3) -- (3, 4.8);
\draw (-3, 4.8) -- (-3, 4) -- (5, 4) -- (5, 4.8);
\draw[->] (-1, 3) to (spamaddition);
\draw[->] (1, 4) to (useaddition);
\draw (-0.8, -0.1) -- (0.8, -0.1);

\draw[->] (0,-0.1) -- (0,-1.8);
\node at (0,-2) {Anzahl Spam-Mails \(\leq\) Anzahl Nicht-Spam-Mails};
\end{tikzpicture}
\caption{High-Level Struktur des Dominierende-Ausgabe-Schaltkreises}
\label{fig:circuit:max sum}
\end{figure}
\requirement{Dieser Schaltkeris f\"ur die dominierende Ausgabe 
kann generiert werden}

\subsection{Feststellen ob Ausgabe eindeutig}\label{sec:id3:case2}
\begin{figure}
\begin{phases}
\aliceknowledge[-2]{Vorwissen};
\aliceknowledge[2]{Eigene diskretisierte E-Mails};

\bobknowledge[-2]{Vorwissen};
\bobknowledge[2]{Eigene diskretisierte E-Mails};

\phase{Phase 4.2: Feststellen ob Ausgabe eindeutig}

\symmetricknowledge{gemeinsamer Blattknoten mit eindeutiger Ausgabe}
\end{phases}
\caption{ID3-Algorithmus, Fall 2: Ausgabe eindeutig}
\label{fig:id3:case2}
\end{figure}
Es muss ein Schaltkreis designed werden, der Feststellt, ob alle Elemente
einer Menge eindeutig sind und dann entweder das Klassenlabel oder ein 
Fehlersymbol ausgibt. Die Eingabe ist somit f\"ur jede E-Mail eine
Kodierung f\"ur Spam, Nicht Spam oder Abwesenheit, die Anzahl der Eingaben
ist bekannt und durch die Gesamtanzahl der E-Mails beschr\"ankt.\\
Wir implementieren diesen Schaltkreis dann als Zustandsmaschine, die die
internen Zust\"ande ,,Alles bis hier Spam'', ,,Alles bis hier kein Spam''
und ,,Bereits uneindeutig'' hat. Wenn dann 
\(T \colon \mathrm{State} \times \mathrm{Mailtype}\) ist, muss folgende
Zustands\"ubergangstabelle implementiert werden:\\
\begin{center}
\begin{tabular}{c c c c}
T & Alles bis hier Spam & Alles bis hier kein Spam & Bereits uneindeutig\\
Spam & Alles bis hier Spam & Uneindeutig & Bereits Uneindeutig \\
Nicht Spam & Uneindeutig & Alles bis hier kein Spam & Bereits Uneindeutig \\
Abwesenheit & Alles bis hier Spam & Alles bis hier kein Spam & Bereits uneindeutig
\end{tabular}
\end{center}
Zudem w\"are es sehr angenehm, wenn die Kodierung von Spam und 
,,Alles bis hier Spam'' und von ,,Nicht Spam'' und ,,Alles bis hier kein Spam''
gleich sind, da dies den Anfangsfall vereinfacht.\\
Wenn wir nun ,,Bereits uneindeutig'' durch 11 kodieren und 
,,Alles bis hier Spam'' mit 01 kodieren und ,,Alles bis hier kein Spam''
mit 00 kodieren und davon ausgehend ,,Spam'' als 01 kodieren und
,,Nicht Spam'' als 00 und ,,Abwesenheit'' als 11, dann muss folgende
Zustands\"ubergangstabelle gelten:\\
\begin{center}
\begin{tabular}{c c c c}
T & 01 & 00 & 11\\
01 & 01 & 11 & 11\\
00 & 11 & 00 & 11\\
11 & 01 & 00 & 11
\end{tabular}
\end{center}

Durch Anwenden von KV-Diagrammen ergeben sich als Zustands\"ubergangsgleichungen
somit, mit \(s_0, s_1\) als Bits des vorherigen Zustandes, \(e_0, e_1\) als Bits
der E-Mail Kodierung und \(s_0', s_1'\) als Bits des neuen Zustandes:
\begin{align*}
s_0' &=& s_0 \vee \overline{s_1} \overline{e_0} e_1
           \vee s_1 \overline{e_0} \overline{e_1}\\
s_1' &=& s_1 \vee \overline{e_0} e_1
\end{align*}
Der Anfangszustand des Automatens ist die Kodierung der Klasse der ersten E-Mail.
Es muss dann nur noch f\"ur jede E-Mail das beschriebene Zustands\"ubergangsnetz
von den vorherigen Zust\"anden und der Kodierung der Klasse der aktuellen
E-Mail implementiert werden. Das Fehlersymbol, das ausgegeben wird, ist 11,
andernfalls ist die Klasse im zweiten Ausgabebit Kodiert, wobei Spam als 1 
kodiert ist und Nicht Spam als 0.

\subsection{Das Entropien-Protokoll}
Es muss in diesem Teilschritt f\"ur jeden Anwender ein Share von
 \(x\cdot \ln x\) berechnet werden, sodass die Summe der Shares
 ca \(x \cdot \ln x\) ist.
Um den ersten Schritt mit Yaos Algorithmus zu berechnen, m\"ussen
wir einige Teilprobleme l\"osen. Es muss zum einen ein Weg gefunden
werden, durch den man mit Yaos Protokoll f\"ur beide Anwender
verschiedene Ausgaben produziert werden k\"onnen und zum zweiten muss
ein Weg gefunden werden, eine Zahl in zwei Shares zu zerlegen, sodass die
Summe der Shares wieder die Zahl ist.

\subsubsection{Erweiterung von Yaos Protokoll:  Separate Ausgaben}
Betrachten wir das erste Teilproblem, separate Ausgaben f\"ur die Anwender
zu erzeugen. Dies ist ein Problem, da Yaos Protokoll fuer die private 
zwei Parteien berechnung einer Funktion eben eine Funktion berechnet, d.h.
genau einen Wert, der dann beiden Parteien bekannt gegeben wird. 
Um dies zu l\"osen, nehmen wir an, dass i und j die Eingaben von Alice
und Bob sind und der evaluierte Schaltkreis \(f(i, j) = A \& B\) berechnet,
wobei \(\&\) die Konkatenation von Bin\"arsequenzen bezeichne.
Falls die Ausgabe nicht derartig sortiert ist, muss dies in einem separaten
Schaltkreis vor der Ausgabe passieren. Wir erweitern dann die Eingabe i
von Alice um \(\|A\|\) Zufallsbits zu \(i \& C_A\) und analog die Eingabe
j von Bob um \(\|B\|\) Zufallsbits zu \(j \& C_B\) und erweitern den 
Schaltkreis am Ende, sodass er 
\(f'(i\&C_A, j\&C_B) = A \oplus C_A \& B \oplus C_B\) berechnet, wobei
\(\oplus\) das bitweise XOR von zwei Bin\"arsequenzen beschreibe. Da \(C_A\)
und \(C_B\) im eigentlichen Schaltkreis zur Berechnung von A und B nicht
verwendet werden und zuf\"allig sind und dem jeweils anderen Anwender 
unbekannt sind, ist dies also \"aquivalent zu einer 
One-Time-Pad-Verschl\"usselung der Ergebnisse mit einem Sch\"ussel, den
nur der Anwender kennt, der diese Ausgabe wisssen soll.\\
\requirement{Es ist m\"oglich, einen Schaltkreis so zu erweitern}

\subsubsection{Erweiterung von Yaos Protokoll: Zerlegung der Ausgabe in zuf\"allige Shares}
\paragraph{Die Problemstellung}
Zum zweiten muss ein bin\"arkodierter Integer \(S\) in zwei zuf\"allige Shares 
\(S_A, S_B\) zerlegt werden, sodass \(S_A + S_B = S\) ist. Da unsere
Schaltkreise deterministisch sind, bedeutet das, dass wir Zufallsbits als 
Eingabe hinzugeben m\"ussen, um eine zuf\"allige Aufteilung zu erreichen.
Wir l\"osen dieses Problem dann so, dass wir einen Verteilungsvektor \(V\)
berechnen mit \(\|V\| = \|S\|\) und kopieren das Bit i in Alice' Share \(S_A\),
falls \(V^i = 1\) ist, andernfalls kopieren wir das Bit i in Bobs Share \(S_B\).
Das Kopieren kann implementiert werden, indem \(S_A^i = S^i \wedge V^i\) und
\(S_B^i = S^i \wedge \overline{V^i}\) implementiert wird.

\paragraph{Unsere L\"osung}
Die Summe der beiden Shares ist dann wieder S, weil die Shares den Wert von
S als zwei disjunkte Mengen von Zweierpotenzen darstellen, sodass die Addition
keinen Carry erfordert, sondern einfach eine Veroderung der beiden Shares ist.
Somit wird S wieder entstehen, wenn jedes Bit in \(S_A\) oder in \(S_B\) zu
finden ist. Das ist nach Konstruktion aequivalent dazu, dass jedes Bit in V
entweder 0 oder 1 ist. Bleibt die Frage, wieviele Informationen aus dem Share
gewonnen werden kann. Es gilt, dass eine 0 eine Unsicherheitsquelle ist, da
die 0 entweder eine 0 sein kann, die enstanden ist, weil der Verteilungsvektor
an dieser Position ung\"unstig war oder weil wirklich im Share eine 0 war.
Wenn wir eine 1 sehen, wissen wir auf jeden Fall, dass in \(S\) an dieser
Position 1 war. Da wir jedoch als Menge aufzuteilender Werte zum einen den
Wert \(2^N \cdot n \cdot \ln 2\) haben f\"ur eine Konstante \(N\) und zum
anderen \(\epsilon \cdot 2^N\) f\"ur ein beiden Parteien unbekanntes
Epsilon, sind die vorkommenden Bitmuster so \"uberlappend, dass nur aus der
Position einiger 1en nicht geschlossen werden kann, welcher Wert aufgetreten 
ist. Wenn zudem der Verteilungsvektor unbekannt ist, ist somit aus dem Share
auf jeden Fall nicht ausreichend Informationen abzuleiten, um das Geheimnis
zu lernen.

\paragraph{Berechnung des Verteilungsvektors}
Es bleibt nun V zu berechnen. Da die Bitbreite von \(S\) abgesch\"atzt werden
kann, definieren wir, dass Alice und Bob zwei weitere Vektoren \(V_A\) und
\(V_B\) eingeben und definieren \(V = V_A \oplus V_B\). Dadurch kann keiner
der beiden Anwender alleine den Wert von V zu seinem Vorteil beeinflussen.\\
Im \(x \cdot \ln x\) Entropienprotokoll wird nun eine Taylorreihe aufgestellt,
anhand derer festgestellt werden kann, das zwei Werte berechnet werden m\"ussen:
\(2^N \cdot n \cdot \ln 2\) und \(\epsilon \cdot 2^N\), wobei x die
Summe der Anwendereingaben ist und \(x = 2^n\cdot(1+\epsilon)\) mit 
\(-\frac{1}{2} \leq \epsilon \leq \frac{1}{2}\) und N eine obere Schranke
f\"ur n ist. Der erste Wert ist kein Integer, kann jeoch auf einen Integer
gerundet werden, ohne dass die Genauigkeit einbricht, da er nur als
Anfangsann\"aherung dient, der zweite Wert ist ein Integer.
\requirement{Es ist m\"oglich, einen Schaltkreis so zu erweitern}

\subsubsection{Berechnung der Anfangsapproximation}
Der erste Wert wird in einem Schaltkreis berechnet, indem das n berechnet wird
und die m\"oglichen Werte des Ausdruckes in einer hardkodierten Tabelle
nachgesehen werden. Das n wird berechnet, indem der Index des signifikantesten
Bits von x berechnet wird. Der zweite Ausdruck wird berechnet, indem 
\(\epsilon \cdot 2^N = 2^(N-n) \cdot \epsilon \cdot 2^n = 2^(N-n) \cdot (x - 2^n)\) 
festgestellt wird. Das bedeutet, man muss das signifikanteste Bit von x 
l\"oschen und das Ergebnis davon um N-n bit nach links shiften. Der Wert
von N wird vorher berechnet und hardkodiert.Die Lookuptable und der 
parametrierte Shift werden wieder \"uber vollst\"andige Suchen implementiert,
da so nur der (relativ einfache) Vergleich implementiert werden muss.
Danach sind diese beiden Werte berechnet und ausgehend von der Vor\"uberlegung
muss noch die Aufteilung beider Werte in Shares sowie die Verschleierung der
Ausgaben f\"ur die beiden Anwender orthogonal hinzugef\"ugt werden.\\
\requirement{Dieser Schaltkreis zur Berechnung der Shares der
ersten Approximation kann generiert werden}

\subsubsection{Verbesserung der ersten Approximation}
\paragraph{Vorgehensweise}
Um dann die Anfangsapproximation zu verbessern, wird die Taylorreihe bis auf
das k. Element berechnet, wobei k ein Praezisionsparameter ist. 
\cite{privateid3} w\"ahlt hierzu eine zuf\"allige Zahl \(z_1\) und definiert
das Polynom:
\begin{equation}
Q(z) = 
    \mathrm{lcm}(2,\dots,k)
    \cdot
    \sum_{i=1}^k 
    \frac{(-1)^{i-1}}{2^{N \cdot (i-1)}}
    \cdot
    \frac{(\alpha_1+z)^i}{i}
    - z_1
\end{equation}
F\"ur die Implementierung wird der binomische Term aufgel\"ost und die Formel
etwas umgestell:
\begin{equation}
Q(z) =
    \mathrm{lcm}(2, \dots, k)
    \cdot
    \sum
        _{
            i=1
        }
        ^k
    \sum
        _{
            x=1
        }
        ^i
    \frac
        {
            (-1)
                ^{
                    i-1
                }
        }
        {
            2
                ^{
                    N \cdot (i-1)
                }
            \cdot 
            i
        }
    \cdot
    {i \choose x}
    \cdot
    \alpha_1
        ^{i-x}
    \cdot
    z
        ^x
    - z_1
\end{equation}
In dieser Form kann prinzipiell ein Array mit den Koeffizienten als Eintr\"age
verwendet werden und immer an der Stelle x wird der entsprechende Faktor
addiert.
\paragraph{Geheime Auswertung von Q}
\subparagraph{Die Problemstellung}
Die Auswertung von Q im Punkt \(\alpha_2\) ergibt dann ein zweites Share 
\(z_2\) mit der Eigenschaft, dass 
\(z_1 + z_2 + lcm(2,\dots,k)\cdot(\beta_1+\beta_2) \approx 
lcm(2,\dots,k)\cdot 2^N \cdot \ln x\). Die Gleichheit gilt nur ungef\"ahr,
da die Taylorapproximation nur teilweise berechnet wurden, jedoch kann
die Genauigkeit durch den Parameter k (zu Lasten der Laufzeit, da k der Grad
des auszuwertenden Polynoms ist)  beliebig verbessert werden.\\
Da Q einen geheimen Share von Alice enth\"ahlt und \(\alpha_2\) ein
geheimer Share von Bob ist, brauchen wir einen Algorithmus zur
geheimen Auswertung von Polynomen, sodass Bob zwar \(Q(\alpha_2)\) lernt, 
aber nicht Q und dass Alice nichts \"uber \(\alpha_2\) erf\"ahrt.
\subparagraph{Das verwendete Protokoll}
Das dazu verwendete Protokoll basiert auf \cite{ot} arbeitet wie folgt:
Alice w\"ahlt ein zuf\"alliges bivariates Polynom \(R(x, y)\) mit den 
Eigenschaften:  
 (1) Der Grad \(d_y\) von y ist der Grad von Q
 (2) \(R(0,\cdot) = Q(\cdot)\),
 (3) Der Grad von x in Q ist ein Parameter \(d_{R,x}\).
So ein Polynom kann gew\"ahlt werden, indem wir mit dem Polynom Q
anfangen und dann Zufallskoeffizienten f\"ur Terme, die den Parameter
x enthalten, w\"ahlen, bis der Grad in x gross genug ist. Dadurch
kann durch setzen von x = 0 direkt das Polynom Q rekonstruiert werden,
da nur die Faktoren aus Q keinen Anteil am x haben. Wenn wir desweiteren
keine zu grossen Potenzen von y einf\"ugen ist die 1. Bedingung ebenfalls
direkt erf\"ullt.  Die dritte Bedingung ist nach Konstruktion erf\"ullt.\\
Bob w\"ahlt ein weiteres univariates Polynom S mit der Eigenschaft, dass
\(S(0) = \alpha_2\) ist und der Grad des Polynoms ist \(\frac{d_{R,x}}{d_Q}\),
wobei \(d_Q\) der Grad von Q ist. Dies kann konstruiert werden, indem 
der konstante Faktor des Polynoms auf \(\alpha_2\) gesetzt wird und
die restlichen Faktoren zuf\"allig gew\"ahlt werden.

Der Plan ist nun, ein Polynom \(T(0) = R(0,S(0)) = P(S(0)) = P(\alpha_2)\)
auszuwerten, damit Bob den gesuchten Wert lernen kann. um T rekonstruieren
zu k\"onnen muss Bob dementsprechend 
\(d_T + 1 = d_{R,x} + d_Q \cdot d_s +1= 2\cdot d_{R,x}+1\) 
Punkte von T erfahren,
um T zu rekonstruieren und \(T(0)\) auswerden zu k\"onnen. (Die verschiedenen
\(d_p\) bzw \(d_{p,v}\) bezeichnen den Grad des Polynoms p, eventuell in der
Variablen v). Um dies geheim durchzuf\"uhren, w\"ahlt Bob \(n = 2 \cdot d_{R,x}+1\)
verschiedene Punkte verschieden von 0. F\"ur jeden Punkt \(x_i\) dieser Punkte
sendet Bob eine Liste von m-1 zuf\"alligen Punkten und dem Wert \(S(x_i)\) 
in zuf\"alliger Reihenfolge an Alice sowie den Punkt \(x_i\) selbst.
Via 1-m-Oblivious-Transfer kann nun Alice den Wert \(R(x_i, \cdot)\) f\"ur jeden
der zuf\"alligen Punkte anbieten und Bob kann -- da er die Reihenfolge der
Punkte und damit die Position von \(S(x_i)\) kennt -- den Wert \(R(x_i, S(x_i))\)
lernen. Alice lernt dabei die Position nicht und deswegen den Wert \(S(x_i)\)
nicht und Bob erf\"ahrt keinen der anderen Werte. Danach interpoliert Bob T und berechnet 
\(T(0)\)
\requirement{Dieses Protokoll zur Polynomauswertung kann ausgef\"uhrt werden.}

\paragraph{1-out-of-N Oblivious Transfer}
\subparagraph{Die Problemstellung}
Es verbleibt nun ein Protokoll f\"ur den 1-out-of-N Oblivious Transfer zu
w\"ahlen. Um zu rekapitulieren, Alice kennt N Werte 
\(I_A^1, I_A^2, \dots, I_A^N \in \{0,1\}^m \)
und Bob kennt einen Index \(i_B\). Das Ziel des Protokolles ist nun, dass Bob
\(I_A^{i_B}\) lernt, ohne dass Bob \(I_A^{j}\) f\"ur \(j \neq i_B\) lernt und
ohne dass Alice \(i_B\) lernt.

\subparagraph{Das verwendete Protokoll}
Es sei \(\{F_k : \{0,1\}^m \mapsto \{0,1\}^m\} | K \in \{0,1\}^t\) eine Familie
von pseudozuf\"alligen Funktionen. Wir verwenden nun diese Funktionen und
1-out-of-2-Oblivious Transfer (f\"ur den bereits eine Spezifikation existiert),
um die 1-out-of-N Oblivious Transfer zu implementieren.

Alice berechnet nun l Schl\"usselpaare
\((K_1^0, K_1^1), (K_2^0, K_2^1), \dots, (K_l^0, K_l^1))\) mit \(N = 2^l\),
sodass alle Schl\"ussel Schl\"ussel f\"ur die pseudo-zuf\"allige Funktion F
sind. Desweiteren berechnet Alice 
\(Y_s = i_A^s \oplus \bigoplus_{j=1}^l F_{K_j^{s \rhd j}}(s)\), wobei \(s \rhd j\) das
Bit mit Index j von s ist. Bob w\"ahlt nun aus jedem der l Paare via
1-out-of-2-Oblivious-Transfer eines aus. 
Wenn Bob den Wert mit Index \(i_B\) lernen will, dann muss Bob im Schritt j
den Eintrag \(i_B \rhd j\) w\"ahlen. Desweiteren sendet Alice die Strings \(Y_s\) an Bob.
Dann ist Bob in der Lage, \(i_A^{i_B}\) zu rekonstruieren, indem er
\(Y_{i_B} \oplus \bigoplus_{j=1}^l F_{K_j}^{i_B \rhd j}(i_B)\) berechnet,
denn:
\begin{align*}
& & Y_{i_B} \oplus \bigoplus_{j=1}^l F_{K_j}^{i_B \rhd j}(i_B)\\
&=& i_A^{i_B} 
        \oplus \bigoplus_{j=1}^l F_{K_j^{i_B \rhd j}}(i_B) 
        \oplus \bigoplus_{j=1}^l F_{K_j^{i_B \rhd j}}(i_B)\\
&=& i_A^{i_B}
\end{align*}

\requirement{Dieses Protokoll zum 1-out-of-N-Oblivious Transfer kann
ausgef\"uhrt werden.}

\subparagraph{Die Familie pseudozuf\"alliger Funktionen}
Es verbleibt die Familie \(F_k\) von Funktionen zu spezifizieren. Ausgehend von
\cite{constructrandom} funktioniert dies wie folgt: Wir w\"ahlen einen 
kryptographisch sicheren Zufallsbit-generator G, der einen Seed der L\"ange
k auf \(2\cdot k\) Bit erweitert. Wir bezeichnen dann mit \(G^0(k)\) die erste
H\"alfte von \(G(k)\) und mit \(G^1(k)\) die zweite H\"alfte von \(G(k)\). Ist
nun \(i\) ein Bitstring der L\"ange l, dann definieren wir 
\(G^i(x) = G^{i \rhd 1}(G^{i \rhd 2}(\dots G^{i \rhd l}(x) \dots))\), d.h. der
Zufallszahlengenerator wird immer wieder aufgerufen und es wird in der 
,,richtigen'' H\"alfte weitergerechnet. Wir definieren dann eine Familie 
von Funktionen \(\{F_k\}\) wobei wir \(F_k(x) = G_x(k)\) definieren.\\
\requirement{Es ist so eine Funktionsfamilie implementiert.}

Um zu rekapitulieren, Alice und Bob kennen nun beide Shares \(\beta_1, z_1\) bzw 
\(\beta_2, z_2\), sodass
\((z_1 + lcm(2,\dots,k)\cdot\beta_1) + (z_2 + lcm(2,\dots,k)\cdot\beta_2)
 = lcm(2,\dots,k)\cdot2^N\cdot\ln x\) ist.\\

\subsubsection{Private Multiplikation}
\paragraph{Die Problemstellung}
Wir definieren nun ein Protokoll, welches f\"ur die Eingaben \(i_A, i_B\) 
zuf\"allige Shares \(o_A, o_B\) produziert, sodass \(o_A + o_B = i_A \cdot i_B\)
gilt. Dadurch kann
\(x \cdot \ln x = E_A \cdot \ln (E_A + E_B) + E_B \cdot \ln (E_A + E_B)\) berechnet
werden, wenn \(E_A\) die Anzahl E-Mails von Alice ist und \(E_B\) die Anzahl E-Mails
von Bob, was insgesamt dann die gesuchte Entropie ist.

\paragraph{Das verwendete Protokoll}
Alice definiert das Polynom \(Q(z) = i_A \cdot z + r_A\) f\"ur einen
zuf\"allig gew\"ahlten Wert \(r_A\). Beide wenden nun die geheime 
Polynomauswertung an, sodass Bob \(Q(i_B)\) berechnet. Wir definieren
dann \(o_A = r_A\) und \(o_B = Q(i_B)\). Es gilt dann direkt, dass
\(o_A + o_B = r_A + i_A \cdot i_B + r_A = i_A \cdot i_B\) ist und
\(o_A, o_B\) sind wirklich zuf\"allig und geheim, da zum Berechnen von 
(beispielsweise) \(o_B\) aus \(i_A\) und \(o_A\) eine Gleichung
mit zwei Unbekannten \(Q(a_2), a_2\) gel\"ost werden m\"usste, was
nicht eindeutig m\"oglich ist und der Privatheit der Polynomauswertung.\\
\requirement{Dieses Protokoll zur Multiplikation kann ausgef\"uhrt werden}

\subsubsection{Das gesamte Protokoll}
Das komplette Protokoll zum berechnen f\"ur \(x \cdot \ln x\) mit 
Eingaben \(i_A, i_B\) und \(x = i_A + i_B\) besteht nun aus
drei Phasen: Wir berechnen zuerst die Shares \(l_A, l_B\) von 
\(\ln x\) nach dem ersten Teilprotokoll. 
Wir wenden dann das zweite Teilprotokoll zur Multiplikation zweimal
an, einmal auf die Eingabe \(l_A, i_B\) und einmal auf der Eingabe
\(l_B, i_A\) und erhalten die Shares \(m_A^1, m_A^2, m_B^1\) und \(m_B^2\)
mit \(m_A^1 + m_B^1 = l_A \cdot i_B\) und 
\(m_A^2 + m_B^2 = l_B \cdot i_A\). Wir definieren dann Alice Ausgabe des
gesamten \(x \cdot \ln x\)-Protokolls als 
\(o_A =  m_A^1 + m_A^2 + l_A \cdot i_A\) und Bobs Ausgabe analog als
\(o_B = m_B^1 + m_B^2 + l_B \cdot i_B\). Es gilt dann:
\begin{align*}
o_A + o_B &=& m_A^1 + m_A^2 + l_A \cdot i_A + m_B^1 + m_B^2 + l_B \cdot i_B\\
          &=& l_A \cdot i_B + l_B \cdot i_A + l_A \cdot i_A + l_B \cdot i_B\\
          &=& i_A \cdot (l_A + l_B) + i_B \cdot ( l_A + l_B )\\
          &=& (i_A + i_B) \cdot \ln (i_A + i_B)
\end{align*}
Zeile 2 folgt aus Zeile 1 durch ersetzen von \(m_A^1 + m_B^1\)
bzw \(m_A^2 + m_B^2\), die restlichen Zeilen ergeben sich durch 
wiederholtes Ausklammern. Somit ist die Korrektheit des Protokolles
gezeigt. Die Privatheit des Protokolles folgt aus der Privatheit
der einzelnen Schritte sowie der Undurchsichtigkeit der 
berechneten Shares.\\
\requirement{Die Entropie-Shares k\"onnen anhand diesse Protokolles berechnet
werden}

\subsection{Attribut mit maximalem Informationsgewinn finden}\label{sec:id3:case3}
\begin{figure}
\begin{phases}
\aliceknowledge[-2]{Vorwissen};
\aliceknowledge[2]{Eigene diskretisierte E-Mails};

\bobknowledge[-2]{Vorwissen};
\bobknowledge[2]{Eigene diskretisierte E-Mails};

\phase{Phase 4.3: Berechnen der Entropien}

\symmetricknowledge{Gemeinsame Entropien}

\phase{Phase 4.4: Attribut mit maximalem Informationsgewinn finden}

\symmetricknowledge{Gemeinsames bestes aktuelles Attribut}

\phase{Phase 4: Rekursion}

\symmetricknowledge{gemeinsamer Klassifikator}
\end{phases}
\caption{ID3-Algorithmus, Fall 3: Erzeugung eines Astes}
\label{fig:id3:case3}
\end{figure}
\paragraph{Problemstellung}
Gegeben das obige Protokoll kann nun die Berechnung des Attributes
mit dem maximalen Informationsgewinn einfach durchgef\"uhrt werden.
Es wird f\"ur jedes Attribut das Entropienprotokoll angewendet. Wir
erhalten dadurch einen Vektor von Shares 
\(s_A^{a_1}, s_A^{a_2}, \dots, s_A^{a_k}\) f\"ur Alice und einen 
Vektor von Shares \(S_B^{a_1}, S_B^{a_2}, \dots, s_B^{a_k}\) f\"ur
Bob, wobei \(a_1, a_2, \dots, a_k\) die Attribute sind. Wir m\"ussen
nun in diesem Vektor den Index mit der minimalen Summe finden, denn wenn
die Reihenfolge der Attribute fix und \"offentlich ist, kann durch
diesen Index bestimmt werden, welches Attribut die geringste Entropie
und damit den gr\"ossten Informationsgewinn hat.\\
\paragraph{Unsere L\"osung}
Wir verwenden erneut einen Automaten, der die einzelnen Shares 
sequentiell abarbeitet und dessen interner Zustand der Index und der
Wert des aktuell besten Shares ist. Die Eingabe des Automaten sind
immer ein Paar von Shares f\"ur das gleiche Attribut sowie der
Index dieses Attributes. Wenn \(S_m, i_m\) der interne Zustand
des Automaten ist, wobei \(S_m\) die bisher minimale Summe von
Shares ist und \(i_m\) der Index dieser Shares und \(S_A, S_B\)
die aktuellen Eingabeshares sind und \(i\) der Index der aktuellen
Eingabe ist, dann muss der Automat folgenden Zustands\"ubergang
implementieren:
\begin{align*}
S_m' &=& \:\mathrm{if} \: S_A + S_B < S_m \: \mathrm{then} \: S_A + S_B \: \mathrm{else} \: S_m \\
i_m' &=& \: \mathrm{if} \: S_A + S_B < S_m \: \mathrm{then} \: i \: \mathrm{ else } \: i_m
\end{align*}
Wenn wir dies als einen Schaltkreis implementieren k\"onnen, 
k\"onnen wir diesen Zustands\"ubergangschaltkreis f\"ur alle
eingegebenen Shares wiederholen. Der Anfangszustand ist
das erste Paar Shares.

\subparagraph{Bedingte Zuweisung}
Gegeben die Zuweisung 
\begin{equation}
x = \: \mathrm{if} \: b \: \mathrm{then} \: t \: \mathrm{else} \: f
\end{equation}
und den Fakt, dass ein Schaltkreis \(B\) mit einer Ausgabe
\(o_B\) existiert, sodass \(o_B = 1\) ist genau dann wenn
b wahr ist, dann kann  die Zuweisung implementiert werden
durch:
\begin{equation}
x = t \wedge o_B \vee f \wedge \overline{o_B}
\end{equation}
Im Fall dass b wahr ist, ist \(o_B = 1\) und somit
gilt \(f \wedge \overline{o_B} = 0\) und damit gilt
insgesamt \(x = t\). Im Fall, dass b falsch ist, ist
\(o_B = 0\) und somit gilt \(t \wedge o_B = 0\) und
insgesamt gilt \(x = f\). Somit ist dieser Teilschaltkreis
korrekt. Desweiteren werden wir die Indizes der Attribute
hart in den Schaltkreis kodieren. 

\subparagraph{Vergleichen}
F\"ur bin\"arkodierte Integer a, b gilt, dass \(a \le b\) gilt,
wenn im ersten unterschiedlichen Bit von a und b in der Stelle von b eine 1 
und in der Stelle von a eine 0 steht. Damit kann dies erneut einfach als
Automat implementiert werden, der die Zahlen a, b vom signifikantesten
Bit zum wenigsten signifikanten Bit liest und die Zust\"ande 
,,unentschieden'', ,,Ergebnis positiv'' und ,,Ergebnis negativ'' besitzt.
Die Eingabe des Automaten sind die 2 Bits von a, b. Die Zustands\"ubergangstabelle
ist somit:
\begin{center}
\begin{tabular}{r|c c c c}
\(a_i, b_i \rightarrow \) & 1, 1 & 1, 0 & 0, 1 & 0, 0\\
\hline
unentschieden & unentschieden & Ergebnis negativ & Ergebnis positiv & unentschieden \\
Ergebnis positiv & Ergebnis positiv & Ergebnis positiv & Ergebnis postiv & Ergebnis positiv \\
Ergebnis negativ & Ergebnis negativ & Ergebnis negativ & Ergebnis negativ & Ergebnis positiv 
\end{tabular}
\end{center}

Wir kodieren dann ,,unentschieden'' mit 00, ,,Ergebnis negativ'' mit 10 und
,,Ergebnis positiv'' mit 11. Damit ergibt sich die bin\"are Zustands\"ubergangstabelle:\\
\begin{center}
\begin{tabular}{c|c c c c}
\(a_i, b_i \rightarrow\) & 11 & 10 & 01 & 00 \\
00 & 00 & 10 & 11 & 00 \\
11 & 11 & 11 & 11 & 11 \\
10 & 10 & 10 & 10 & 10 \\
\end{tabular}
\end{center}
Wenn nun \(s_0, s_1\) die Zustandsbits des Automaten sind, ergeben sich
als Zustands\"ubergangsgleichungen die Gleichungen:
\begin{align}
s_0' &=& s_0 \vee a_i \oplus b_i\\
s_1' &=& s_1 \vee \overline{s_0} \wedge \overline{s_1} \wedge \overline{a_i} \wedge b_i\\
\end{align}
Diese Gleichungen machen Sinn, da \(s_0\) kodiert, ob bereits
ein Ergebnis gespeichert wird und wenn ein Ergebnis vorhanden
ist oder \(a_i\) und \(b_i\) unterschiedlich sind, bleibt ein
Ergebnis gesetzt. Im zweiten Zustandsbit ist kodiert,
ob das Ergebnis positiv oder negativ ist. Es wird entweder einfach
kopiert oder gesetzt, wenn der Zustand vorher ,,unentschieden'' war
und \(a_i\) 0 ist und \(b_i\) 1. Der Anfangszustand ist \(s_0 = s_1 = 0\).
Diese Zustands\"ubergangsgleichungen k\"onnen nun durch ein
einfaches Schaltnetz implementiert werden und einfach f\"ur alle
Attribute wiederholt werden.

\subparagraph{Summieren}
Wir berechnen die Summe wieder durch einen einfachen Ripple-Carry-Adder.\\

\requirement{Dieses Protokoll kann implementiert werden}

\pagebreak  %XXX: if  possible, kill this pagebreak
\section{Verwenden des Klassifikators}
Es muss zus\"atzlich zum Lern-Programm ein Programm geschrieben
werden, welches den Klassifikator auf eine Menge von E-Mails anwendet.
Wir bieten hierzu ein Programm an, welches den Klassifikator in einem
einfachen Textformat einliest und diesen auf eine Menge von E-Mails
anwendet. Diese Menge von E-Mails ist als Dateien in einem Verzeichnis
gegeben und f\"ur jeden Dateinamen wird eine Klassifikation als Spam
oder Not Spam ausgegeben.
\subsection{Eingabe des Klassifikators}
Ausgehend von den Definitionen eines Attributes und eines Entscheidungsbaumes
kann leicht eine Grammatik erzeugt werden, welche die Form des eingegebenen
Klassifikators eindeutig bestimmt. Wir notieren diese Grammatik in BNF. Diese
ist so gew\"ahlt, dass sie eine LL(1)-Grammatik ist, d.h., sie ist besonders
einfach zu parsen.\\
\begin{verbatim}
tree -> `Decide' `(' attribute (`,' tree)+ `)'
      | `Output' `(' class `)'.
class -> `Spam' | `Not Spam'.
attribute -> `(' word `,' probability `,' probabilty `)'.
word ->   (`a' | `b' | ... | `z' | `A' | ... | `Z')+
probability -> number `.' number .
number -> (`0' | `1' | ... | `9')+.
\end{verbatim}

Somit w\"are ein kodierter Klassifikationsbaum beispielsweise:
\begin{verbatim}
Decide((Foo, 0.3, 0.6),
        Output(Spam), 
        Decide((Bar, 0.5, 0.6), 
                Output(Spam), 
                Output(Not Spam)
              )
      )
\end{verbatim}

Die Produktion ,,probability'' beschreibt eine Zahl, die sich als
eine Folge von Ziffern vor einem Dezimalpunkt und einer Folge von
Ziffern nach dem Dezimalpunkt beschreiben lassen. Dies sind alle
reellen Zahlen, und da wir keine komplexen Zahlen betrachten, sondern
nur Verh\"altnisse von nat\"urlichen Zahlen zueinander ist diese
Darstellung ausreichend, um alle m\"oglichen Zahlenwerte darzustellen.
Da die Buchstabenmenge als die lateinischen Klein- und Grossbuchstaben
definiert ist und ein Wort definiert ist als Sequenz dieser Zeichen,
ist die Produktion ,,word''  ausreichend, um alle m\"oglichen Worte
darzustellen. Damit ergibt sich, dass die Produktion 
,,attribute'' in der Lage ist, alle Attribute, die in dieser
Anwendung auftreten k\"onnen, darzustellen.\\
Es gibt desweiteren bei uns nur die Ausgaben ,,Spam'' und ,,Nicht Spam''.
Damit ist die Produktion ,,class'' ausreichend, um alle 
m\"oglichen Ausgaben des Baumes darzustellen. Daraus folgt, dass die
zweite Produktion von tree in der Lage ist, alle m\"oglichen Bl\"atter
darzustellen. Desweiteren folgt induktiv aus der Vollst\"andigkeit der
Produktion ,,attribute'' und der Darstellbarkeit der Bl\"atter als
Induktionsanfang, dass die erste Produktion von tree in der Lage ist,
alle m\"oglichen auszugebenden Entscheidungsb\"aume darzustellen. Damit
ist die Grammatik m\"achtig genug f\"ur unsere Zwecke.\\
Es ist weiterhin zu bemerken, dass eine semantische Validierung notwendig
ist, da in der Grammatik weder gefordert ist, dass der untere Schwellwert
eines Attributes wirklich kleiner ist als der obere Schwellwert 
eines Attributes noch dass beide Schwellwerte zwischen 0 und 1 liegen, noch
dass die Anzahl der Teilb\"aume richtig ist. Damit ergeben sich die folgenden
Akzeptanzkriterien:\\
\requirement{Der Klassifizierer weist die Eingabe Decide((Foo, 0.5,2),
Output(Spam), Output(Spam)) wegen eines zu grossen Schwellwertes zur\"uck}
\requirement{Der Klassifizierer weist die Eingabe Decide((Foo, 2, 3),
Output(Spam), Output(Spam)) wegen eines zu grossen Schwellwertes zur\"uck}
\requirement{Der Klassifizierer weist die Eingabe Decide((Foo, 1, 0),
Output(Spam), Output(Spam)) wegen falsch sortierter Schwellwerte zur\"uck}
\requirement{Der Klassifizierer weist die Eingabe Decide((Foo, 0.2, 0.3),
Output(Spam), Output(Spam)) wegen zuweniger Teilb\"aume zur\"uck}
\requirement{Der Klassifizierer weist die Eingabe Decide((Foo, 0.2, 0.3),
Output(Spam), Output(Spam), Output(Spam), Output(Spam)) wegen zuvieler
Teilb\"aume zur\"uck}
\requirement{Der Klassifizierer akzeptiert die Eingabe 
Decide((Foo, 0.2, 0.3), 
    Output(Spam),
    Decide((Bar, 0.3, 0.4)
        Output(Spam),
        Output(Not Spam), 
        Output(Spam)),
    Output(Spam))}
\requirement{Der Klassifizierer akzeptiert die Eingabe Decide((Foo, 0, 0.5),
Output(Spam), Output(Spam))}
\requirement{Der Klassifizierer akzeptiert die Eingabe Decide((Foo, 0.5, 1),
Output(Spam), Output(Spam))}
\requirement{Der Klassifizierer akzeptiert die Eingabe 
Decide((Foo, 0.5, 0.5)), Output(Spam), Output(Spam))}
\requirement{Der Klassifizierer akzeptiert die Eingabe Decide((Foo, 0, 0),
Output(Spam))}
\requirement{Der Klassifizierer akzeptiert die Eingabe Decide((Foo, 1, 1),
Output(Spam))}
\subsection{Arbeitsweise des Klassifikators}
Der Klassifikator bekommt als Eingabe ein Verzeichnis mit E-Mails und eine
Datei meinem einem Klassifikator. Den Klassifikator liest er ein und
speichert ihn intern. Danach traversiert der Klassifikator das gegebene
Verzeichnis rekursiv und behandelt jede Datei, die er in diesem Verzeichnis
findet als E-Mail-Inhalt. (Dadurch ist es m\"oglich, die Trainingsdaten auch
als Versuchsdaten zu benutzen, ohne sie zu bewegen).\\
F\"ur jede E-Mail wird dann der Inhalt der E-Mail eingelesen und die
Klassifikation durch den eingegebenen Klassifikator durchgef\"uhrt, d.h., 
f\"ur jeden Ast werden die Vorkommnisse des Wortes im Attribut
festgestellt und rekursiv im entsprechenden Teilbaum weiterklassifiziert
und in einem Blatt wird die Klasse festgestellt. Diese festgestellte Klasse
wird dann zusammen mit dem relativen Pfad vom eingegebenen Verzeichnis
ausgegeben.\\
Wenn also beispielsweise folgende Verzeichnisstruktur gegeben ist:
\begin{verbatim}
mails/hank/mail1
mails/hank/mail2
mails/bob/mail1
\end{verbatim}
und wir annehmen, dass der eingegebene Klassifikator E-Mails mit dem Index
1 als Spam erkennt und E-Mails mit dem Index 2 als Nicht Spam, dann
w\"are die Ausgabe:
\begin{verbatim}
hank/mail1 Spam
hank/mail2 Not Spam
bob/mail1 Spam
\end{verbatim}
Damit ergeben sich folgende Akzeptanzkriterien:\\
\requirement{Gegeben der Klassifikator Decision((Bar, 0.3, 0.6), Output(Spam),
Output(Not Spam), Output(Spam)), dann wird die E-Mail "Bar Foo Foo Foo" als
Spam klassifiziert}
\requirement{Gegeben der Klassifikator Decision((Bar, 0.3, 0.6), Output(Spam),
Output(Not Spam), Output(Spam)), dann wird die E-Mail "Bar, Bar, Foo, Foo" als
Not Spam klassifiziert}
\requirement{Gegeben der Klassifikator Decision((Bar, 0.3, 0.6), Output(Spam),
Output(Not Spam), Output(Spam)), dann wird die E-Mail "Bar, Bar, Bar, Foo" als
Spam klassifiziert}
\requirement{Gegen der Klassifikator Decision((Bar, 0.3, 0.6), Output(Spam),
Output(Not Spam), Output(Spam)) und eine Verzeichnisstruktur wie oben
skizziert, wobei hank/mail1 "Bar Foo Foo Foo", hank/mail2 "Bar Bar Foo Foo"
und bob/mail1 "Bar Bar Bar Foo" enth\"alt, dann wird die oben als Beispiel
genannte Ausgabe produziert (oder in einer anderen Reihenfolge}

\section{References}
\bibliography{references}{}
\bibliographystyle{plain}
\end{document}
