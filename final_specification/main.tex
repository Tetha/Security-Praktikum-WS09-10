\documentclass{article}
\usepackage{tikz}
\usepackage{todonotes}
\usepackage{amssymb}
\usetikzlibrary{arrows,decorations.pathmorphing}

\hyphenation{Schwell-werte}
% =============== Definitionen =========
\newenvironment{definition}
    [1]
    {
        {\bf Definition:} #1\\
    }
    {}

\newcommand{\defined}
    [1]
    {
        {\bf #1}
    }
% ======================================

% =============== Requirements =========
\newcounter{requirementscount}{}
\setcounter{requirementscount}{0}
\newcommand{\requirement}[1] {
        \addtocounter{requirementscount}{1}
        {\bf Requirement \therequirementscount:} #1\\
    }

% =============== PHASES ===============
\newcounter{ycounter}{}
\newenvironment{phases}
{
\setcounter{ycounter}{-1}
\begin{tikzpicture}[node distance=3cm,text width=3cm,
    box/.style={shape=rectangle,draw}]
}
{\end{tikzpicture}}

\newcommand{\nomoreheaders} {
    \addtocounter{ycounter}{-1}
}

\newcommand{\aliceheader}[1] {
\node at (-4,\theycounter) {#1}
}
\newcommand{\bobheader}[1] {
\node at (4,\theycounter) {#1}
}

\newcommand{\aliceknowledge}[2][0]{
\node[box]
    at (-4+#1, \theycounter)
    {#2}
}
\newcommand{\bobknowledge}[2][0]{
\node[box]
    at (4+#1, \theycounter)
    {#2}
}

\newcommand{\symmetricknowledge}[2][0]{
\aliceknowledge{#2};
\bobknowledge[#1]{#2};
}


\newcommand{\phase}[1]{
\addtocounter{ycounter}{-1};
\draw[->,decorate,decoration={snake,amplitude=1mm,post length=2mm}]
    (0,\theycounter) -- ++(0,-2)
    node [right,midway,xshift=3mm] {#1};
\addtocounter{ycounter}{-3};
}
% ======================================

\begin{document}
\listoftodos
\pagebreak
\tableofcontents
\pagebreak
\section{Einleitung}
\todo[inline]{Struktur vom Dokument erl\"autern}
\subsection{Begriffe}
\begin{definition}{Eigenes,Gesamtes}
\(M\) sei eine Menge von Elementen, die in zwei Teilmengen \(M_A\)
und \(M_B\) zerf\"allt, sodass \(M = M_A \cup M_B\) ist. Wir nehmen
desweiteren an, dass Alice \(M_A\) kennt, aber weder \(M\) noch \(M_B\)
und dass foo Bob \(M_B\) kennt, aber weder \(M\) noch \(M_A\). Dann bezeichnen
wir:
\begin{itemize}
\item \(M\) als \defined{gesamtes} Wissen
\item \(M_A\) als das \defined{eigene} Wissen von Alice
\item \(M_B\) als das \defined{eigene} Wissen von Bob
\item \(M_B\) als das \defined{andere} Wissen von Alice
\item \(M_A\) als das \defined{andere} Wissen von Bob
\end{itemize}
\end{definition}
\begin{definition}{Gemeinsam}
Wenn beide Anwender das gleiche Wissen w haben, dann bezeichnen wir w
als \defined{gemeinsames Wissen}. 
\end{definition}\\
\begin{definition}{Vorwissen}
Wenn Anwender verschiedene Phasen hintereinander ausf\"uhren, dann bezeichnen
wir das Wissen aus den bereits ausgef\"uhrten Phasen als \defined{Vorwissen}.
\end{definition}\\
\todo[inline]{Definition: Entscheidungsbaum}
\begin{definition}{Attribut}
Wir definieren eine Menge von Wahrscheinlichkeiten 
\(P = [0, 1] \subset \mathbb{R}\) und eine Menge von Buchstaben 
\(\Sigma = \{a, b, \dots, z, A, B, \dots, Z\}\).
Damit definieren wir ein \defined{Attribut} als 
\(\Sigma^+ \times P \times P\). Wenn ein Attribut \(A = (w, l, h)\) gegeben ist,
bezeichnen wir w als \defined{Wort}, l als \defined{unterer Schwellwert} und h
als \defined{oberer Schwellwert}. Es wird desweiteren von allen Attributen
gefordert, dass \(l \leq h\) ist.
\end{definition}\\
\todo[inline]{Definition: Schaltkreis}
\todo[inline]{Definition: Entstellter Schaltkreis}
\subsection{Annahmen}
\todo[inline]{Annahme: ehrliche anwender := "handeln nach protokoll"}

\pagebreak
\section{Grundlagen der Anwendung}
\todo[inline]{Vision der Anwendung}

\subsection{Form der Benutzereingabe}
\todo[inline]{Festlegen, wie die E-Mails ins Programm kommen}

\subsection{Interaktion der verteilten Programme}
\todo[inline]{Festlegen, wie das Programm verteilt wird und die Teile kommunizieren}

\subsection{Phasen der Anwendung}
\todo[inline]{Kurz die Einzelnen phasen der Anwendung beschreiben}
\begin{figure}[htb]
\centering
\begin{phases}
\aliceheader{Alice};
\bobheader{Bob};
\nomoreheaders
\aliceknowledge[-2]{eigene E-Mails};
\bobknowledge[-2]{eigene E-Mails};

\aliceknowledge[2]{Einordnung von eigenen E-Mails als Spam, Nicht Spam};
\bobknowledge[2]{Einordnung von eigenen E-Mails als Spam, Nicht Spam};

\phase{Phase 1: Finden der gemeinsamen Wortliste};

\symmetricknowledge{Gemeinsame Wortliste};

\phase{Phase 2: Finden der gemeinsamen Schwellwerte};

\symmetricknowledge{Gemeinsame Attribute = Liste von (Wort + Schwellwerte)};
\phase{Phase 3: Diskretisieren der eigenene E-Mails};

\symmetricknowledge{Eigene diskretisierte E-Mails};

\phase{Phase 4: Lernen der gesamten E-Mails};

\symmetricknowledge{Gemeinsamer Klassifikator};
\end{phases}
\caption{Phasen der Anwendung}
\end{figure}


\pagebreak % XXX: if possible, kill this pagebreak
\section{Finden der gemeinsamen Wortliste}
\todo[inline]{Einleitung, Verweisen auf Figure f\"ur gemeinsame Wortliste}
\begin{figure}[htb]
\begin{phases}
\aliceheader{Alice};
\bobheader{Bob};
\nomoreheaders

\aliceknowledge[-2]{eigene E-Mails};
\bobknowledge[-2]{eigene E-Mails};

\aliceknowledge[2]{Einordnung von eigenen E-Mails als Spam, Nicht Spam};
\bobknowledge[2]{Einordnung von eigenen E-Mails als Spam, Nicht Spam};
\phase{Phase 1.1: Berechnung der Vorkommnisse der Worte in eigenen Spam/Nicht Spam E-Mails};
\symmetricknowledge[1]{Liste von (Wort + Anteil der Vorkomnisse eines Wortes an allen eigenen Worten)};
\phase{Phase 1.2: Auswahl der eigenen Worte nach Informationsheuristik, Auswahl der N besten eigenen Worten};
\symmetricknowledge{Eigene Wortliste}
\phase{Phase 1.3: Synchronisierung der Wortlisten}
\symmetricknowledge{Gemeinsame Wortliste}
\end{phases}
\caption{Schritte zum Berechnen der gemeinsamen Wortliste}
\end{figure}

\todo[inline]{F\"ur section-Titel besseren Begriff f\"ur "Vorkomnisse der Worte in eigenen Spam/Nicht Spam E-Mails" finden}
\subsection{Berechnung der Vorkomnisse}
\todo[inline]{Content}
\subsection{Auswahl der Worte nach Informationsheuristik}
Wir wollen nun Worte ausw\"ahlen, die m\"oglichst viel \"uber die Klasse
der E-Mail aussagen, damit wir m\"oglichst aussagekr\"aftige Attribute
f\"ur den Baum verwenden. Wir verwenden die Heuristik, dass ein Wort
mehr \"uber die Klasse der E-Mail aussagt, wenn die Wahrscheinlichkeit,
dass das Wort in einer der beiden Klassen mit signifikant gr\"osserer
Wahrscheinlichkeit auftritt. Das bedeutet, wir wollen Worte selektieren,
bei denen die Wahrscheinlichkeiten, in Spam-E-Mails bzw in Nicht-Spam-E-Mails
sich drastisch unterscheiden. Eine m\"ogliche Quantifizierung dieser 
Unterschiedlichkeit ist \(\Delta(x, y) = \|x - y\|\). \(\Delta\) hat die
Eigenschaft, f\"ur x = 1 und y = 0 bzw x = 0 und y = 1 maximal 1 zu sein,
und f\"ur identische x und y 0 zu sein. Da x und y f\"ur die Belegung
(0, 1) bzw (1, 0) wirklich maximal weit auseinander liegen und bei 
gleichen Werten wirklich die gerinstm\"ogliche Aussage \"uber die Klasse
der Mail getroffen wird, ist dies wirklich eine Quantifizierung der
Aussagekraft, die wir anstreben. Daher w\"ahlen wir die m\"oglichst
aussagekr\"aftigen E-Mails aus, indem wir alle Worte nach 
\(\Delta(\mathrm{Vorkommen~in~Spam-E-Mails}, 
         \mathrm{Vorkommen~in~Nicht-Spam-E-Mails})\) 
absteigend sortieren und die ersten N Worte w\"ahlen. Damit ergeben
sich folgende Akzeptanzkriterien:\\
\requirement{Wenn N = 2 ist, und als Worte gegeben sind:
\begin{tabular}{c c c}
A & 0.5 & 0.5 \\
B & 0.2 & 0.2 \\
C & 0.3 & 0.5 \\
D & 0.2 & 0.8 \\
E & 0.9 & 0.2
\end{tabular}
dann werden als Wortliste D und E gew\"ahlt.}

\subsection{Syncronisierung der Wortlisten}
\todo[inline]{Content}

\pagebreak % XXX: if possible, kill this pagebreak
\section{Finden der gemeinsamen Schwellwerte}
\todo[inline]{Einleitung, auf Figure f\"ur Schwellwerte verweisen}

\begin{figure}[htb]
\begin{phases}
\aliceheader{Alice};
\bobheader{Bob};
\nomoreheaders

\aliceknowledge[-2]{Vorwissen};
\aliceknowledge[2]{Gemeinsame Wortliste};

\bobknowledge[-2]{Vorwissen};
\bobknowledge[2]{Gemeinsame Wortliste};
\phase{Phase 2.1: Berechnung der Vorkommnisse der Worte in eigenen Spam/Nicht Spam E-Mails};
\symmetricknowledge[1]{Eigene Liste von (Wort + Anteil der Vorkomnisse eines Wortes an Spam/Nicht-Spam Worten)};
\phase{Phase 2.2: Bestimmung eines Schwellwertes, der Spam, Nicht-Spam Anteile m\"oglichst halbiert};
\symmetricknowledge{Eigene Liste von (Wort + Schwellwert)};
\phase{Phase 2.3: Synchronisierung der Schwellwerte};
\symmetricknowledge{Gemeinsame Liste von (Wort + Schwellwerte)};
\end{phases}
\end{figure}
\todo[inline]{F\"ur section-Titel besseren Begriff f\"ur "Vorkomnisse der Worte in eigenen Spam/Nicht Spam E-Mails" finden}
\subsection{Berechnung der Vorkomnisse}
\todo[inline]{Content}
\subsection{Bestimmung der eigenen Schwellwerte}
\todo[inline]{Content}
\subsection{Syncronisierung der Schwellwerte}
\todo[inline]{Content}

\pagebreak % XXX: if possible, kill this pagebreak
\section{Diskretisieren der eigenen E-Mails}
\todo[inline]{Einleitung, Figure referenzieren}
\todo[inline]{Content}
\begin{figure}[htb]
\begin{phases}
\aliceheader{Alice};
\bobheader{Bob};
\nomoreheaders;
\aliceknowledge[-2]{Vorwissen};
\aliceknowledge[2]{Gemeinsame Attribute = Liste von (Wort + Schwellwerte)};

\bobknowledge[-2]{Vorwissen};
\bobknowledge[2]{Gemeinsame Attribute = Liste von (Wort + Schwellwerte)};

\phase{Phase 3: Diskretisieren der eigenene E-Mails};
\symmetricknowledge{Eigene diskretisierte E-Mails};
\end{phases}
\end{figure}

\pagebreak % XXX: if possible, kill this pagebreak
\section{Lernen der gesamten E-Mails}
\todo[inline]{verteiltes ID3 beschreiben}

\subsection{Yaos Protokoll}
\begin{figure}[htb]
\begin{phases}
\aliceheader{Alice};
\bobheader{Bob};
\nomoreheaders
\symmetricknowledge{Eigene Eingabe};
\phase{Y.1: Konstruktion des entstellten Schaltkreises und \"Ubertragung};
\aliceknowledge[-2]{Eingabekodierung};
\aliceknowledge[2]{Schaltkreis};
\bobknowledge{Schaltkreis};
\phase{Y.3 Alice schickt kodierte Eingabe an Bob};
\bobknowledge{Alice' kodierte Eingabe};
\phase{Y.4 Via Oblivious Transfer wird Bob's Eingabe kodiert};
\bobknowledge{Bob's kodierte Eingabe};
\phase{Y.5 Bob wertet Schaltkreis aus und sendet die Ausgabe an Alice};
\symmetricknowledge{Ausgabe} ;
\end{phases}
\caption{Yaos Algorithmus}
\end{figure}
\todo[inline]{Yaos algorithmus grundlegend zusammenfassen (garbled decision table, garbled gate, garbled circuit)}
\todo[inline]{Verschl\"usselung f\"ur die garbled Circuits festlegen (RSA?)}
\todo[inline]{1-2 Oblivious Transfer festlegen (mit RSA?)}
\todo[inline]{Feststellung der benoetigten Bytezahl beschreiben}


\subsection{Feststellen der dominierenden Ausgabe}
\begin{figure}[htb]
\begin{phases}
\aliceknowledge[-2]{Vorwissen};
\aliceknowledge[2]{Eigene diskretisierte E-Mails};

\bobknowledge[-2]{Vorwissen};
\bobknowledge[2]{Eigene diskretisierte E-Mails};

\phase{Phase 4.1: Feststellen der dominierenden Ausgabe};

\symmetricknowledge{gemeinsamer Blattknoten mit dominierender Ausgabe};
\end{phases}
\caption{ID3-Algorithmus, Fall 1: Keine Attribute mehr vorhanden}
\end{figure}
\todo[inline]{Schaltkreis designen: Maximum von Summen von positiven Zahlensequenzen}

\subsection{Feststellen ob Ausgabe eindeutig}
\begin{figure}[htb]
\begin{phases}
\aliceknowledge[-2]{Vorwissen};
\aliceknowledge[2]{Eigene diskretisierte E-Mails};

\bobknowledge[-2]{Vorwissen};
\bobknowledge[2]{Eigene diskretisierte E-Mails};

\phase{Phase 4.2: Feststellen ob Ausgabe eindeutig}

\symmetricknowledge{gemeinsamer Blattknoten mit eindeutiger Ausgabe}
\end{phases}
\caption{ID3-Algorithmus, Fall 2: Ausgabe eindeutig}
\end{figure}
\todo[inline]{Schaltkreis designen: Gleichheit.}

\subsection{Das Entropien-Protokoll}
\todo[inline]{Schaltkreis f\"ur x * log x -Protokoll aus dem Paper zusammenfassen}

\subsection{Attribut mit maximalem Informationsgewinn finden}
\begin{figure}[htb]
\begin{phases}
\aliceknowledge[-2]{Vorwissen};
\aliceknowledge[2]{Eigene diskretisierte E-Mails};

\bobknowledge[-2]{Vorwissen};
\bobknowledge[2]{Eigene diskretisierte E-Mails};

\phase{Phase 4.3: Berechnen der Entropien}

\symmetricknowledge{Gemeinsame Entropien}

\phase{Phase 4.4: Attribut mit maximalem Informationsgewinn finden}

\symmetricknowledge{Gemeinsames bestes aktuelles Attribut}

\phase{Phase 4: Rekursion}

\symmetricknowledge{gemeinsamer Klassifikator}
\end{phases}
\caption{ID3-Algorithmus, Fall 3: Erzeugung eines Astes}
\end{figure}
\todo[inline]{Vorgheen zusammenfassen, Schaltkreis aus dominierender Ausgabe wiederverwenden}

\pagebreak  %XXX: if  possible, kill this pagebreak
\section{Verwenden des Klassifikators}
Es muss zus\"atzlich zum Lern-Programm ein Programm geschrieben
werden, welches den Klassifikator auf eine Menge von E-Mails anwendet.
Wir bieten hierzu ein Programm an, welches den Klassifikator in einem
einfachen Textformat einliest und diesen auf eine Menge von E-Mails
anwendet. Diese Menge von E-Mails ist als Dateien in einem Verzeichnis
gegeben und f\"ur jeden Dateinamen wird eine Klassifikation als Spam
oder Not Spam ausgegeben.
\subsection{Eingabe des Klassifikators}
Ausgehend von den Definitionen eines Attributes und eines Entscheidungsbaumes
kann leicht eine Grammatik erzeugt werden, welche die Form des eingegebenen
Klassifikators eindeutig bestimmt. Wir notieren diese Grammatik in BNF. Diese
ist so gew\"ahlt, dass sie eine LL(1)-Grammatik ist, d.h., sie ist besonders
einfach zu parsen.\\
\begin{verbatim}
tree -> `Decide' `(' attribute (`,' tree)+ `)'
      | `Output' `(' class `)'.
class -> `Spam' | `Not Spam'.
attribute -> `(' word `,' probability `,' probabilty `)'.
word ->   (`a' | `b' | ... | `z' | `A' | ... | `Z')+
probability -> number `.' number .
number -> (`0' | `1' | ... | `9')+.
\end{verbatim}

Somit w\"are ein kodierter Klassifikationsbaum beispielsweise:
\begin{verbatim}
Decide((Foo, 0.3, 0.6),
        Output(Spam), 
        Decide((Bar, 0.5, 0.6), 
                Output(Spam), 
                Output(Not Spam)
              )
      )
\end{verbatim}

Die Produktion ,,probability'' beschreibt eine Zahl, die sich als
eine Folge von Ziffern vor einem Dezimalpunkt und einer Folge von
Ziffern nach dem Dezimalpunkt beschreiben lassen. Dies sind alle
reellen Zahlen, und da wir keine komplexen Zahlen betrachten, sondern
nur Verh\"altnisse von nat\"urlichen Zahlen zueinander ist diese
Darstellung ausreichend, um alle m\"oglichen Zahlenwerte darzustellen.
Da die Buchstabenmenge als die lateinischen Klein- und Grossbuchstaben
definiert ist und ein Wort definiert ist als Sequenz dieser Zeichen,
ist die Produktion ,,word''  ausreichend, um alle m\"oglichen Worte
darzustellen. Damit ergibt sich, dass die Produktion 
,,attribute'' in der Lage ist, alle Attribute, die in dieser
Anwendung auftreten k\"onnen, darzustellen.\\
Es gibt desweiteren bei uns nur die Ausgaben ,,Spam'' und ,,Nicht Spam''.
Damit ist die Produktion ,,class'' ausreichend, um alle 
m\"oglichen Ausgaben des Baumes darzustellen. Daraus folgt, dass die
zweite Produktion von tree in der Lage ist, alle m\"oglichen Bl\"atter
darzustellen. Desweiteren folgt induktiv aus der Vollst\"andigkeit der
Produktion ,,attribute'' und der Darstellbarkeit der Bl\"atter als
Induktionsanfang, dass die erste Produktion von tree in der Lage ist,
alle m\"oglichen auszugebenden Entscheidungsb\"aume darzustellen. Damit
ist die Grammatik m\"achtig genug f\"ur unsere Zwecke.\\
Es ist weiterhin zu bemerken, dass eine semantische Validierung notwendig
ist, da in der Grammatik weder gefordert ist, dass der untere Schwellwert
eines Attributes wirklich kleiner ist als der obere Schwellwert 
eines Attributes noch dass beide Schwellwerte zwischen 0 und 1 liegen, noch
dass die Anzahl der Teilb\"aume richtig ist. Damit ergeben sich die folgenden
Akzeptanzkriterien:\\
\requirement{Der Klassifizierer weist die Eingabe Decide((Foo, 0.5,2),
Output(Spam), Output(Spam)) wegen eines zu grossen Schwellwertes zur\"uck}
\requirement{Der Klassifizierer weist die Eingabe Decide((Foo, 2, 3),
Output(Spam), Output(Spam)) wegen eines zu grossen Schwellwertes zur\"uck}
\requirement{Der Klassifizierer weist die Eingabe Decide((Foo, 1, 0),
Output(Spam), Output(Spam)) wegen falsch sortierter Schwellwerte zur\"uck}
\requirement{Der Klassifizierer weist die Eingabe Decide((Foo, 0.2, 0.3),
Output(Spam), Output(Spam)) wegen zuweniger Teilb\"aume zur\"uck}
\requirement{Der Klassifizierer weist die Eingabe Decide((Foo, 0.2, 0.3),
Output(Spam), Output(Spam), Output(Spam), Output(Spam)) wegen zuvieler
Teilb\"aume zur\"uck}
\requirement{Der Klassifizierer akzeptiert die Eingabe 
Decide((Foo, 0.2, 0.3), 
    Output(Spam),
    Decide((Bar, 0.3, 0.4)
        Output(Spam),
        Output(Not Spam), 
        Output(Spam)),
    Output(Spam))}
\requirement{Der Klassifizierer akzeptiert die Eingabe Decide((Foo, 0, 0.5),
Output(Spam), Output(Spam))}
\requirement{Der Klassifizierer akzeptiert die Eingabe Decide((Foo, 0.5, 1),
Output(Spam), Output(Spam))}
\requirement{Der Klassifizierer akzeptiert die Eingabe 
Decide((Foo, 0.5, 0.5)), Output(Spam), Output(Spam))}
\requirement{Der Klassifizierer akzeptiert die Eingabe Decide((Foo, 0, 0),
Output(Spam))}
\requirement{Der Klassifizierer akzeptiert die Eingabe Decide((Foo, 1, 1),
Output(Spam))}
\subsection{Arbeitsweise des Klassifikators}
Der Klassifikator bekommt als Eingabe ein Verzeichnis mit E-Mails und eine
Datei meinem einem Klassifikator. Den Klassifikator liest er ein und
speichert ihn intern. Danach traversiert der Klassifikator das gegebene
Verzeichnis rekursiv und behandelt jede Datei, die er in diesem Verzeichnis
findet als E-Mail-Inhalt. (Dadurch ist es m\"oglich, die Trainingsdaten auch
als Versuchsdaten zu benutzen, ohne sie zu bewegen).\\
F\"ur jede E-Mail wird dann der Inhalt der E-Mail eingelesen und die
Klassifikation durch den eingegebenen Klassifikator durchgef\"uhrt, d.h., 
f\"ur jeden Ast werden die Vorkommnisse des Wortes im Attribut
festgestellt und rekursiv im entsprechenden Teilbaum weiterklassifiziert
und in einem Blatt wird die Klasse festgestellt. Diese festgestellte Klasse
wird dann zusammen mit dem relativen Pfad vom eingegebenen Verzeichnis
ausgegeben.\\
Wenn also beispielsweise folgende Verzeichnisstruktur gegeben ist:
\begin{verbatim}
mails/hank/mail1
mails/hank/mail2
mails/bob/mail1
\end{verbatim}
und wir annehmen, dass der eingegebene Klassifikator E-Mails mit dem Index
1 als Spam erkennt und E-Mails mit dem Index 2 als Nicht Spam, dann
w\"are die Ausgabe:
\begin{verbatim}
hank/mail1 Spam
hank/mail2 Not Spam
bob/mail1 Spam
\end{verbatim}
Damit ergeben sich folgende Akzeptanzkriterien:\\
\requirement{Gegeben der Klassifikator Decision((Bar, 0.3, 0.6), Output(Spam),
Output(Not Spam), Output(Spam)), dann wird die E-Mail "Bar Foo Foo Foo" als
Spam klassifiziert}
\requirement{Gegeben der Klassifikator Decision((Bar, 0.3, 0.6), Output(Spam),
Output(Not Spam), Output(Spam)), dann wird die E-Mail "Bar, Bar, Foo, Foo" als
Not Spam klassifiziert}
\requirement{Gegeben der Klassifikator Decision((Bar, 0.3, 0.6), Output(Spam),
Output(Not Spam), Output(Spam)), dann wird die E-Mail "Bar, Bar, Bar, Foo" als
Spam klassifiziert}
\requirement{Gegen der Klassifikator Decision((Bar, 0.3, 0.6), Output(Spam),
Output(Not Spam), Output(Spam)) und eine Verzeichnisstruktur wie oben
skizziert, wobei hank/mail1 "Bar Foo Foo Foo", hank/mail2 "Bar Bar Foo Foo"
und bob/mail1 "Bar Bar Bar Foo" enth\"alt, dann wird die oben als Beispiel
genannte Ausgabe produziert (oder in einer anderen Reihenfolge}
\end{document}
